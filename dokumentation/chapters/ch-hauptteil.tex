% Bsp. eines Hauptteils

\chapter{Ziel des Projekts}
\label{sec:grundl}
Ziel des Projektes ist es, eine Software zu entwickeln, die den File-IO von Anwendungen analysiert. Die Software soll sich dabei zwischen das zu analysierende Programm und das Betriebssystem schalten und s\"amtlichen File-IO abfangen. Der File-IO des Programms soll anschliessend gespeichert und graphisch aufbereitet werden. Die Software soll dabei interaktiv sein. Das bedeutet, es soll mit der Software m\"oglich sein, gezielt nach IO-Engp\"assen in einer Anwendung zu suchen.\newline\newline
Ziel ist es dar\"uber hinaus, mit der Software ein Framework zur Analyse von File-IO zu schaffen. Dies bedeutet, dass es m\"oglich sein soll, die Software so zu erweitern, dass mit ihr nicht nur POSIX-IO und MPI-IO, sondern z.B. auch das parallele Dateisystem Lustre analysiert werden kann.\newline\newline
Im ersten Schritt sollen dabei bestehende Softwarel\"osungen evaluiert werden. Im zweiten Schritt geht es dann darum, eine eigene Software zu entwickeln, welche die oben genannten Forderungen erf\"ullt. Die Entwicklung der Software soll dabei portabel mit CMake erfolgen. Die Software soll dar\"uber hinaus Thread-Sicherheit haben. Dies bedeutet, dass sie von mehreren Threads zugleich bedient werden kann. Die Visualisierung soll zudem portabel sein. Die generierten Daten \"uber den File-IO sollen also plattformunabh\"angig bspw. \"uber einen Webserver visualisiert werden k\"onnen.

\chapter{Stand der Technik}
\label{sec:tech}
Im Rahmen der Forschungsarbeit erfolgte zun\"achst eine Marktrecherche, welche Softwarel\"osungen zum Tracing von File-IO bereits auf dem Markt sind. Die L\"osungen, welche den Anforderungen dieses Projektes am ehesten entsprechen wurden dar\"uber hinaus bez\"uglicher ihrer Funktionalit\"at evaluiert. Als wichtigstes Kriterium gilt hierbei, dass es mit der Software sowohl m\"oglich ist POSIX-IO zu untersuchen, als auch MPI-IO. Dar\"uber hinaus soll die Analyse zur Laufzeit ohne Rekompilieren des Codes m\"oglich sein. Dies soll sowohl f\"ur statisch als auch f\"ur dynamisch gelinkte Programme der Fall sein.
\section{Darshan}
Darshan ist ein Programm zur Analyse von POSIX-IO und MPI-IO. Mit Darshan kann ein PDF-Report des File-IOs von Anwendungen erstellt werden. Bei dynamisch gelinkten Programmen ist dies zur Laufzeit m\"oglich, bei statisch gelinkten Programmen ausschliesslich beim Bau des Programms.\newline
Darshan besteht dabei aus zwei Programmen. Mit Darshan-Runtime werden die Informationen \"uber den File-IO eines Programms ermittelt und in einer Log-Datei gespeichert. Die Daten in der Log-Datei k\"onnen anschliessend mit Darshan-Util dargestellt und analysiert werden.
\subsection{Funktionsweise}
Das Sammeln von Informationen zur Laufzeit von Programmen geschieht \"uber die Systemvariable LD\_PRELOAD. Mit dieser ist es m\"oglich Features in ein Prorgamm einzuschleusen. Beim Laden von Shared Libraries wird dabei zun\"achst nicht die eigentliche Bibliothek geladen, sondern diese, welche unter LD\_PRELOAD angegeben wurde. Damit wird dann die Darshan-Bibliothek geladen, welche die IO-Befehle speichert und diese anschliessend an die eigentlichen Bibliotheken weitergibt. Die Funktionsweise von Darshan f\"ur dynamisch gelinkte Programme ist in Abbildung \ref{fig:darshan} dargestellt. Die Bibliothek libdarshan.so wird dabei vom zu untersuchenden Programm \"uber LD\_PRELOAD geladen. Diese speichert alle MPI-IO- und POSIX-IO-Befehle in Log-Dateien. Diese Log-Dateien k\"onnen anschliessend mit Darshan-Util ausgewertet werden. Dabei wird entweder ein PDF-Report kreiert in welchem in Diagrammen u.a. dargestellt wird, wieviele File-IO-Operationen jeweils durchgef\"uhrt wurden und welche Datenmengen dabei verarbeitet wurden. Alternativ k\"onnen die Informationen in eine Textdatei geschrieben und \"uber die Kommandozeile ausgegeben werden.

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{fig/Darshan.JPG}
	\caption{Darshan Aufbau \cite{Mendez.23.06.2016}}
	\label{fig:darshan}
\end{figure}

Das Analysieren von statisch gelinkten Programmen funktioniert \"ahnlich zu VampirTrace mit Compiler-Wrappern. Diese werden beim Bau anstatt der eigentlichen Compiler aufgerufen. Die Wrapper rufen dabei die eigentlichen Compiler auf, erweitern jedoch das zu kompilierende Programm so, dass es mit Darshan analysiert werden kann. \cite{ArgonneNationalLaboratory.22.01.2019}\cite{ArgonneNationalLaboratory.19.01.2019}
\subsection{Fazit}
Darshan ist ein hervorragendes Programm zur Analyse des IO von dynamisch gelinkten Programmen. Der Nachteil liegt dabei jedoch darin, dass der graphische Output nicht interaktiv ist. Es wird zwar ein PDF-Report kreiert, es ist jedoch nicht m\"oglich interaktiv gezielt nach Schwachstellen im Programm zu suchen. Dar\"uber hinaus k\"onnen statisch gelinkte Programme mit Darshan nicht zur Laufzeit ohne erneuten Bau untersucht werden, was ebenfalls einen gravierenden Nachteil darstellt. 
\section{VampirTrace}
VampirTrace ist ein Programm, welches von der Universit\"at Dresden urspr\"unglich zur Analyse von MPI-Programmen entwickelt wurde. Mittlerweile ist es ein Tool-Set zur Analyse von parallelen Programmen im HPC-Bereich. Mit VampirTrace k\"onnen sowohl MPI-IO als auch POSIX-IO untersucht werden. F\"ur die Analyse von Programmen ist es notwendig, diese mithilfe von VampirTrace-Compiler-Wrappern neu zu bauen. Im Makefile m\"ussen dabei die Compiler durch die Compiler-Wrapper von VampirTrace ersetzt werden. Diese rufen dann wiederum die eigentlichen Compiler auf. Die gebauten Programme k\"onnen anschliessend zur Laufzeit mit VampirTrace analysiert werden. Eine Untersuchung zur Laufzeit ohne erneuten Bau ist nicht ohne weiteres m\"oglich.\newline\newline
Die gewonnenen Daten werden von VampirTrace in einer Log-Datei im Open-Trace-Format (OTF) gespeichert. Diese Log-Dateien k\"onnen anschliessend mit Tools, die den Umgang mit OTF beherrschen, visualisiert werden. Am besten eignet sich hierzu das Tool Vampir, welches ebenfalls von der Universit\"at Dresden zu diesem Zweck entwickelt wurde. Mit diesem Tool ist es m\"oglich Daten im OTF-Format interaktiv zu visualisieren und damit gezielt nach Schwachstellen zu suchen.
\cite{TUDresden.2016}\cite{Mendez.23.06.2016}
\section{Score-P}
Score-P ist eine Software, die als Nachfolger von VampirTrace entwickelt wurde. In der Funktionsweise ist Score-P VampirTrace dabei recht \"ahnlich. Die Daten werden ebenfalls im OTF-Format gespeichert und k\"onnen mit VampirTrace visualisiert werden. Alternativ k\"onnen die Daten jedoch auch im TAU-Format gespeichert und mit der Software TAU analysiert werden, welche im n\"achsten Abschnitt erl\"autert wird. F\"ur die Analyse von File-IO ist VampirTrace aber nach wie vor die bessere Alternative.\cite{Kunke.2014}\cite{VirtualInstituteHighProductivitySupercomputing.2018}
\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{fig/Score-P.JPG}
	\caption{Score-P \cite{VirtualInstituteHighProductivitySupercomputing.2018}}
	\label{fig:score-p}
\end{figure}
\section{Ludalo}
Mit Ludalo ist es m\"oglich, Lustre-Metadaten-Operationen zu analysieren. Dies kann in diesem Projekt im weiteren Verlauf erforderlich sein, wenn die Funktionalit\"at der entwickelten Software f\"ur Lustre erweitert werden soll. Lustre ist dabei ein paralleles Dateisystem, welches haupts\"achlich im HPC-Bereich eingesetzt wird.
\cite{Berger.30.07.2014}
\section{TAU}
Tau ist eine Software, entwickelt von der University of Oregon, zur Analyse von parallelen Applikationen. Eine File-IO-Analyse ist dabei sowohl f\"ur POSIX-IO, als auch f\"ur MPI-IO m\"oglich. Die von TAU generierten Daten k\"onnen im OTF-Format gespeichert und anschliessend mit Vampir visualisiert werden. Damit \"Ã¤hnelt TAU stark VampirTrace, wo die Daten ebenfalls mit Vampir visualisiert werden k\"onnen. Die Analyse der Programme erfolgt entweder durch das Recompilieren des Quelltextes oder durch das Laden einer Bibliothek mit LD\_PRELOAD, was jedoch nur bei dynamisch gelinkten Programmen m\"oglich ist. Dies stellt auch den entscheidenden Vorteil von TAU gegen\"uber VampirTrace dar. Die Visualisierung ist bei beiden Tools identisch, allerdings k\"onnen mit TAU dynamisch gelinkte Programme ohne Rekompilieren analysiert werden.
\cite{Shende.03.05.2017}\cite{Shende.2011}\cite{UniversityofOregon.2018}

\section{Fazit}
Keines der untersuchten Programme enth\"alt alle Features, welche in diesem Projekt gew\"unscht sind. Diese sind in Tabelle \ref{tab:Recherche} vergleichend dargestellt.
\begin{table}[h]
	\centering
	\begin{tabular}{l|l|l|l}
		\textbf{} & \textbf{Darshan} & \textbf{VampirTrace}& \textbf{TAU}\\
		\hline
		\textbf{Analyse von POSIX-IO} & + & + & + \\
		\hline
		\textbf{Analyse von MPI-IO} & + & + & + \\
		\hline
		\textbf{Interaktive Bedienung}& - & + & + \\
		\hline
		\textbf{dynamisch gelinkte Programme} & + & - & + \\
		\hline
		\textbf{statisch gelinkte Programme} & - & - & - \\
		\hline
		\textbf{Schwerpunkt auf File-IO-Analyse} & + & - & - \\
	\end{tabular}
	\caption{Marktrecherche}
	\label{tab:Recherche}
\end{table}
Die Analyse von POSIX-IO und MPI-IO ist mit allen untersuchten Produkten m\"oglich. Hinsichtlich der Visualisierung sind sich VampirTrace und TAU \"ahnlich. Bei beiden werden die Daten im OTF-Format gespeichert und k\"onnen mit Vampir untersucht werden, womit auch eine interaktive Bedienung m\"oglich ist. Mit Darshan k\"onnen zwar ebenfalls POSIX-IO und MPI-IO analysiert werden, allerdings kann die Visualisierung durch den PDF-Report oder eine Textdatei nicht interaktiv bedient werden. Der entscheidende Vorteil von Darshan gegen\"uber den anderen Tools ist jedoch, dass es ausschliesslich f\"ur die Analyse von File-IO entwickelt wurde und dadurch deutlich leichtgewichtiger ist.\newline
Die Schwachstelle der Produkte liegt in der Analyse von statisch gelinkten Programmen. Dies ist zwar prinzipiell bei allen m\"oglich, jedoch nur durch das erneute Kompilieren des Quelltextes. Aus diesem Grund soll in diesem Projekt eine eigene Software entwickelt werden, bei welcher dies m\"oglich ist und welche eine interaktive Visualisierung beinhaltet.

\chapter{Entwicklung einer eigenen Software}

Zur Entwicklung einer eigenen Lösung für die Protokollierung und anschließenden Analyse von File-IO sind mehrere Schritte notwendig. Zunächst muss festgelegt werden, welche Daten ausgewertet werden sollen und wie diese erfasst werden können. Nachgelagert folgt dann die Konzeption des gesamten Systems bis hin zur visuellen Aufbereitung der Analyseergebnisse. Mit diesen Schritten befassen sich die folgenden Abschnitte.

\section{File-IO-Konstellationen}
\label{sec:file_io_konstellationen}

Im Folgenden werden unterschiedliche Konstellationen von Dateizugriffen betrachtet, die bei einer Analyse unterschieden werden müssen. Dementsprechend bilden diese Konstellationen auch die Grundlage für die zu protokollierenden Daten. Es müssen ausreichend Daten protokolliert werden um diese Konstellationen erkennen zu können.

\subsection{Konsistenz und Synchronisation}
\label{subsec:konsistenz_und_synchronisation}

Alle folgende Konstellationen beziehen sich auf die Laufzeit eines untersuchten Programms. Zugriffe auf Dateien vor Programmstart und nach Programmende werden nicht betrachtet. Eine Unterscheidung in Threads und Prozesse wird bei der Beschreibung der einzelnen Konstellationen nicht vorgenommen, da beide Varianten sich bezüglich der Synchronisation gleich verhalten. Vereinfachend steht der Begriff Prozess daher für Thread oder Prozess.

\subsubsection{Prozess 0 schreibt einmalig in eine Datei}
\label{subsubsec:prozess_0_schreibt_einmalig_in_eine_datei}

Ein Prozess schreibt einmalig in eine Datei. Die Datei wird durch keinen anderen Prozess beschrieben und durch keinen Prozess gelesen.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node[left] {Zeit} (-1,-1);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-1);
\draw[black] (2,0) node[above] {Datei} -- (2,-1);

\draw[->,red] (0,-0.5) -- node[above,red] {schreiben} (2,-0.5);
\end{tikzpicture}
\caption{Prozess 0 schreibt einmalig in eine Datei}
\label{fig:prozess_0_schreibt_einmalig_in_eine_datei}
\end{figure}

Um diese Konstellation zu erkennen, muss für alle Dateizugriffe des Programms die Datei und die Art des Zugriffs protokolliert werden. Dadurch ist es möglich zu überprüfen, ob nur einmalig schreibend auf eine Datei zugegriffen wird.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen
\end{itemize}

Bei dieser Konstellation ist keine Synchronisation während der Laufzeit des Programms erforderlich. IO kann gefahrlos optimiert werden. Lediglich vor Programmende muss eventuell geprüft werden, ob der Schreibvorgang abgeschlossen ist, damit nachfolgenden Programmen die Daten zur Verfügung stehen. Hierfür muss auch ein Schließen der Datei (POSIX close) protokolliert werden.

\begin{itemize}
 \item Art des Zugriffs: schließen
\end{itemize}

\subsubsection{Prozess 0 schreibt wiederholt in eine Datei}
\label{subsubsec:prozess_0_schreibt_wiederholt_in_eine_datei}

Ein Prozess schreibt wiederholt in eine Datei. Die Datei wird durch keinen anderen Prozess beschrieben und durch keinen Prozess gelesen.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node [left] {Zeit} (-1,-1.5);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-1.5);
\draw[black] (2,0) node[above] {Datei} -- (2,-1.5);

\draw[->,red] (0,-0.5) -- node[above,red] {schreiben} (2,-0.5);
\draw[->,red] (0,-1) -- node[above,red] {schreiben} (2,-1);
\end{tikzpicture}
\caption{Prozess 0 schreibt wiederholt in eine Datei}
\label{fig:prozess_0_schreibt_wiederholt_in_eine_datei}
\end{figure}

Um diese Konstellation zu erkennen sind die gleichen Daten wie bei einem einmaligen Schreiben in eine Datei notwendig \verw{subsubsec:prozess_0_schreibt_einmalig_in_eine_datei}. Neben der Datei selbst und der Art des Zugriffs ist hier allerdings auch noch die Zeit von Interesse. Für Optimierungen des Zugriffs ist die Reihenfolge der Zugriffe entscheidend. Nur wenn die Reihenfolge protokolliert wird, kann bei einer Optimierung das ursprüngliche Ergebnis sichergestellt werden. Hierfür ist auch die genaue Position der geschriebenen Bytes in der Datei wichtig. Nur mit dieser Information kann ein Überschreiben in der Datei oder ein sequenzielles Anhängen an ein Dateiende erkannt und bei einer Optimierung beachtet werden. Um Möglichkeiten zur Optimierung zu erkennen, ist zusätzlich die Dauer eines einzelnen Schreibvorgangs notwendig. Über diese Information kann geprüft werden, ob ein nachfolgender Schreibvorgang auf den vorhergehenden warten muss. Hierfür muss zu den Schreibvorgängen auch noch das eigentliche Öffnen (POSIX open) protokolliert werden. Dies betrifft allerdings die Art des Zugriffs und entspricht daher den oben bereits erwähnten Informationen.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
 \item Zeit: Start- und Endzeitpunkt des Zugriffs
 \item Position: Byteposition und-länge des Zugriffs (bei schreiben und lesen)
\end{itemize}

Bei dieser Konstellation ist eine Synchronisation zwischen den einzelnen Schreibvorgängen notwendig, sofern diese sich gegenseitig überschreiben oder ein vorhergehender Schreibzugriff das Dateiende verschiebt und der aktuelle Vorgang an dieses anknüpft. Im zweiten Fall kann eventuell auf eine Synchronisation über Blockieren nachfolgender Schreibzugriffe verzichtet werden, wenn die Bytelänge und Anzahl der vorhergehenden Schreibvorgänge bekannt ist.

\subsubsection{Prozess 0 liest einmalig aus einer Datei}
\label{subsubsec:prozess_0_liest_einmalig_aus_einer_datei}

Ein Prozess liest einmalig aus einer Datei. Die Datei wird durch keinen anderen Prozess gelesen und durch keinen Prozess beschrieben.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node[left] {Zeit} (-1,-1);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-1);
\draw[black] (2,0) node[above] {Datei} -- (2,-1);

\draw[<-,brown] (0,-0.5) -- node[above,brown] {lesen} (2,-0.5);
\end{tikzpicture}
\caption{Prozess 0 liest einmalig aus einer Datei}
\label{fig:prozess_0_liest_einmalig_aus_einer_datei}
\end{figure}

Um diese Konstellation zu erkennen, sind die gleichen Daten wie bei einem einmaligen Schreiben in eine Datei notwendig \verw{subsubsec:prozess_0_schreibt_einmalig_in_eine_datei}. Das Schließen der Datei ist dabei ebenfalls nur zur Sicherung des Zugriffs durch nachfolgend arbeitende Programme notwendig.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
\end{itemize}

Bei dieser Konstellation ist keine Synchronisation während der Laufzeit des Programms erforderlich. IO kann gefahrlos optimiert werden.

\subsubsection{Prozess 0 liest wiederholt aus einer Datei}
\label{subsubsec:prozess_0_liest_wiederholt_aus_einer_datei}

Ein Prozess liest wiederholt aus einer Datei. Die Datei wird durch keinen anderen Prozess gelesen und durch keinen Prozess beschrieben.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node [left] {Zeit} (-1,-1.5);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-1.5);
\draw[black] (2,0) node[above] {Datei} -- (2,-1.5);

\draw[<-,brown] (0,-0.5) -- node[above,brown] {lesen} (2,-0.5);
\draw[<-,brown] (0,-1) -- node[above,brown] {lesen} (2,-1);
\end{tikzpicture}
\caption{Prozess 0 liest wiederholt aus einer Datei}
\label{fig:prozess_0_liest_wiederholt_aus_einer_datei}
\end{figure}

Diese Konstellation verhält sich analog zum einmaligen Lesen aus einer Datei \verw{subsubsec:prozess_0_liest_einmalig_aus_einer_datei}, da das mehrfache Lesen einer sich nicht verändernden Datei weder beim Erkennen der Konstellation noch zur Synchronisation zusätzliche Anforderungen stellt.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
\end{itemize}

\subsubsection{Prozess 0 liest und schreibt eine Datei}
\label{subsubsec:prozess_0_liest_und_schreibt_eine_datei}

Ein Prozess liest und schreibt wiederholt eine Datei. Die Datei wird durch keinen anderen Prozess gelesen und durch keinen anderen Prozess beschrieben.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node [left] {Zeit} (-1,-2.5);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-2.5);
\draw[black] (2,0) node[above] {Datei} -- (2,-2.5);

\draw[<-,brown] (0,-0.5) -- node[above,brown] {lesen} (2,-0.5);
\draw[->,red] (0,-1) -- node[above,red] {schreiben} (2,-1);
\draw[<-,brown] (0,-1.5) -- node[above,brown] {lesen} (2,-1.5);
\draw[->,red] (0,-2) -- node[above,red] {schreiben} (2,-2);
\end{tikzpicture}
\caption{Prozess 0 liest und schreibt eine Datei}
\label{fig:prozess_0_liest_und_schreibt_eine_datei}
\end{figure}

Um zwischen Lesen und Schreiben unterscheiden zu können, sind mindestens die Informationen zum einmaligen Lesen  \verw{subsubsec:prozess_0_liest_einmalig_aus_einer_datei} und zum einmaligen Schreiben \verw{subsubsec:prozess_0_schreibt_einmalig_in_eine_datei} notwendig. Um konkurrierende und sich gegenseitig blockierende Schreibvorgänge zu identifizieren sind zudem die gleichen Daten wie beim wiederholten Schreiben nötig \verw{subsubsec:prozess_0_schreibt_wiederholt_in_eine_datei}.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
 \item Zeit: Start- und Endzeitpunkt des Zugriffs
 \item Position: Byteposition und-länge des Zugriffs (bei schreiben und lesen)
\end{itemize}

Bei dieser Konstellation ist eine Synchronisation sowohl zwischen den einzelnen Schreibvorgängen als auch zwischen Schreibvorgängen und darauf folgenden Lesevorgängen notwendig. Hier muss also zusätzlich zu den im Abschnitt über wiederholtes Schreiben \verw{subsubsec:prozess_0_schreibt_wiederholt_in_eine_datei} genannten Prüfungen noch überprüft werden, ob ein lesender Zugriff auf zuvor durch Schreibvorgänge veränderte Bytes erfolgt.

\subsubsection{Prozess 0 und Prozess 1 schreiben in eine Datei}
\label{subsubsec:prozess_0_und_prozess_1_schreiben_in_eine_datei}

Mehrere Prozesse schreiben wiederholt in die gleiche Datei. Die Datei wird durch keinen Prozess gelesen.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node [left] {Zeit} (-1,-2);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-2);
\draw[black] (2,0) node[above] {Prozess 1} -- (2,-2);
\draw[black] (4,0) node[above] {Datei} -- (4,-2);

\draw[->,red] (0,-0.5) -- node[above,near start,red] {schreiben} (4,-0.5);
\draw[->,red] (2,-1) -- node[above,red] {schreiben} (4,-1);
\draw[->,red] (0,-1.5) -- node[above,near start,red] {schreiben} (4,-1.5);
\end{tikzpicture}
\caption{Prozess 0 und Prozess 1 schreiben in eine Datei}
\label{fig:prozess_0_und_prozess_1_schreiben_in_eine_datei}
\end{figure}

Neben den Daten zum Erkennen mehrerer Schreibvorgänge \verw{subsubsec:prozess_0_schreibt_wiederholt_in_eine_datei} ist noch eine Information über den jeweiligen Prozess notwendig.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
 \item Zeit: Start- und Endzeitpunkt des Zugriffs
 \item Position: Byteposition und-länge des Zugriffs (bei schreiben und lesen)
 \item Prozess/Thread: Prozess-ID und Thread-Nummer
\end{itemize}

Wie beim wiederholten Schreiben durch einen Prozess \verw{subsubsec:prozess_0_schreibt_wiederholt_in_eine_datei} ist auch in dieser Konstellation eine Synchronisation nötig.

\subsubsection{Prozess 0 und Prozess 1 lesen aus einer Datei}
\label{subsubsec:prozess_0_und_prozess_1_lesen_aus_einer_datei}

Mehrere Prozesse lesen wiederholt aus der gleichen Datei. Die Datei wird durch keinen Prozess beschrieben.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node [left] {Zeit} (-1,-2);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-2);
\draw[black] (2,0) node[above] {Prozess 1} -- (2,-2);
\draw[black] (4,0) node[above] {Datei} -- (4,-2);

\draw[<-,brown] (0,-0.5) -- node[above,near start,brown] {lesen} (4,-0.5);
\draw[<-,brown] (2,-1) -- node[above,brown] {lesen} (4,-1);
\draw[<-,brown] (0,-1.5) -- node[above,near start,brown] {lesen} (4,-1.5);
\end{tikzpicture}
\caption{Prozess 0 und Prozess 1 lesen aus einer Datei}
\label{fig:prozess_0_und_prozess_1_lesen_aus_einer_datei}
\end{figure}

Neben den Daten zum Erkennen mehrerer Lesevorgäng \verw{subsubsec:prozess_0_liest_wiederholt_aus_einer_datei} ist noch eine Information über den jeweiligen Prozess notwendig.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
 \item Prozess/Thread: Prozess-ID und Thread-Nummer
\end{itemize}

\subsubsection{Prozess 0 und Prozess 1 lesen und schreiben eine Datei}
\label{subsubsec:prozess_0_und_prozess_1_lesen_und_schreiben_eine_datei}

Mehrere Prozesse lesen und schreiben wiederholt eine Datei.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\draw[->,black] (-1,0) -- node [left] {Zeit} (-1,-2.5);

\draw[black] (0,0) node[above] {Prozess 0} -- (0,-2.5);
\draw[black] (2,0) node[above] {Prozess 1} -- (2,-2.5);
\draw[black] (4,0) node[above] {Datei} -- (4,-2.5);

\draw[->,red] (0,-0.5) -- node[above,near start,red] {schreiben} (4,-0.5);
\draw[<-,brown] (2,-1) -- node[above,brown] {lesen} (4,-1);
\draw[->,red] (2,-1.5) -- node[above,red] {schreiben} (4,-1.5);
\draw[<-,brown] (0,-2) -- node[above,near start,brown] {lesen} (4,-2);
\end{tikzpicture}
\caption{Prozess 0 und Prozess 1 lesen aus einer Datei}
\label{fig:prozess_0_und_prozess_1_lesen_aus_einer_datei}
\end{figure}

Diese Konstellation stellt eine Kombination aller vorhergehenden Konstellationen dar. Dementsprechend werden alle Daten der einzelnen Konstellationen benötigt.

\begin{itemize}
 \item Datei: Pfad und Dateiname
 \item Art des Zugriffs: öffnen, schreiben, lesen, schließen
 \item Zeit: Start- und Endzeitpunkt des Zugriffs
 \item Position: Byteposition und-länge des Zugriffs (bei schreiben und lesen)
 \item Prozess/Thread: Prozess-ID und Thread-Nummer
\end{itemize}

Hier ist eine Synchronisation zwischen den Schreibvorgängen aller beteiligter Prozesse notwendig. Zudem müssen Lesevorgänge nach Schreibvorgängen gegebenenfalls auch synchronisiert erfolgen (wenn ein zuvor geschriebener Dateiinhalt ausgelesen wird).

\subsection{Metadaten}
\label{subsec:metadaten}

Wenn Metadaten von einem überwachten Programm ausgelesen werden, so muss dies protokolliert werden. Falls kein derartiger Zugriff auf Metadaten protokolliert wurde, kann möglicherweise auf die Erstellung und Aktualisierung von Metadaten verzichtet werden. Dementsprechend könnten Methoden und Dateisysteme ohne Metadaten genutzt werden. Da Metadaten über POSIX-Methoden nicht explizit sondern implizit über jeden ändernden Zugriff auf eine Datei geschrieben werden, muss vor einem Verzicht auf Metadaten allerdings geklärt werden, ob neben dem überwachten Prozess noch nachgelagerte Zugriffe auf die Metadaten stattfinden. Dies kann nicht automatisch geschehen. Daher kann in einem solchen Fall nur eine Empfehlung durch eine Analyse erstellt werden.

\section{Architektur}
\label{sec:architecture}

Wichtig für die Architektur ist neben dem Blick auf das gesamte System auch die Entscheidung für ein geeignetes Datenformat zur Protokollierung und die genaue Gestaltung der Wrapper. Mit einem Wrapper ist in diesem Zusammenhang das Abfangen eines File-IO-Funktionsaufrufes gemeint. Hierfür wird ein Funktionsaufruf an eine andere Funktion (den Wrapper) delegiert und erst von dort aus die ursprünglich gewünschte Funktion aufgerufen. Somit besteht die Möglichkeit im Wrapper zusätzliche Funktionalität auszuführen. Dies kann beispielsweise die Protokollierung von Informationen über den ursprünglichen Funktionsaufruf sein.

\subsection{Datenformat}
\label{subsec:datenformat}

Für die im Abschnitt zu Konsistenz und Synchronisation \verw{subsec:konsistenz_und_synchronisation} aufgeführten Konstellationen müssen durch die Wrapper unterschiedliche Informationen protokolliert werden. Aus diesen Unterschieden ergeben sich folgende Satzarten:

\begin{table}[H]
\centering
\begin{longtabu} { l | X[c,m] | X[c,m] | X[c,m] | X[c,m] | X[c,m] | X[c,m] | X[c,m] }
  Art des Zugriffs & Prozess-ID & Thread-Nr. & Pfad und Datei & Startzeit & Endzeit & Position & Länge \\ \hline
  \endhead
  öffnen & \gut & \gut & \gut & \gut & \gut & \schlecht & \schlecht \\ \hline
  schließen & \gut & \gut & \gut & \gut & \gut & \schlecht & \schlecht \\ \hline
  lesen & \gut & \gut & \gut & \gut & \gut & \gut & \gut \\ \hline
  schreiben & \gut & \gut & \gut & \gut & \gut & \gut & \gut \\
\end{longtabu}
\begin{longtabu} { l l }
  \gut & Datum wird benötigt \\
  \schlecht & Datum wird nicht benötigt \\
\end{longtabu}
\addtocounter{table}{-2}
\caption{Übersicht Satzarten}
\label{table:uebersicht_satzarten}
\end{table}

Es werden neben den oben aufgeführten noch weitere Daten benötigt (z.B. Optionen beim Öffnen einer Datei oder MPI-spezifische Parameter).

Um die benötigten Daten nach dem Protokollieren in eine Datei durch beliebige Anwendungen nutzen zu können \verw{subsec:system} ist ein binäres Format nicht ausreichend. Es wird ein Datenformat benötigt, welches die einzelnen Werte eines Datensatzes selbst beschreibt. Somit setzt das Nutzen der Daten nicht die genaue Kenntnis um Bytelängen und Kodierung der Werte voraus, wie dies bei einem Binärformat der Fall wäre. Als Format kommt somit beispielsweise XML in Frage. Da beim Schreiben der Protokolldatei jedoch auch die Performance wichtig ist, wird ein Format mit möglichst geringem zusätzlichen Aufwand benötigt. Hier erfordert XML durch die Wiederholung der Beschreibung in öffnenden und schließenden Tags zu viele Bytes beim Schreiben der Datei. Dies wirkt sich negativ auf die Dateigröße und die zum Schreiben benötigte Zeit aus. Unter den Formaten mit hoher Verbreitung erfüllt JSON am ehesten die Anforderungen. Die in JSON-Dateien enthaltenen Werte sind als Key-Value-Paare abgelegt und enthalten somit immer einen beschreibenden Text als Key. Zusätzlich sind die eigentlichen Werte im Value-Teil immer als String-Repräsentation kodiert. Weiterhin ist der Daten-Overhead durch die Nutzung weniger Sonderzeichen anstelle von beispielsweise Tags in XML möglichst gering.

\subsection{Wrapper}
\label{subsec:architektur_wrapper}

Wesentlich für die Funktion der Protokollierung ist ein effizientes und vollständiges Abfangen des File-IOs. Dies geschieht über Wrapper, welche die jeweiligen Funktionsaufrufe abfangen und anschließend alle benötigten Daten protokollieren, um danach die ursprünglich gewünschte Funktion aufzurufen. Im Folgenden wird das Wrappen von Funktionsaufrufen von C-Bibliotheken genauer erläutert. Dies geschieht anhand von POSIX-IO und der glibc. Zudem wird die Möglichkeit von direkten Aufrufen des Linux-Kernels ohne vorgeschaltete C-Bibliothek erwähnt, aber aufgrund der geringen Relevanz für dieses Projekt nicht weiter erläutert. Anschließend werden drei mögliche Architekturvarianten für die Wrapper näher erläutert und gegeneinander abgewogen.

Eine Liste der vom Linux-Kernel angebotenen Systemfunktionen kann der Dokumentation in den ,,man-Pages`` entnommen werden\cite{man.syscalls2}. Hier finden sich auch die von POSIX definierten Funktionen, welche ebenfalls in der glibc-Bibliothek als C-Funktionen zur Verfügung stehen.

Bei der Architektur der Wrapper liegt der Fokus insbesondere auf der Performance. Da der zu untersuchende File-IO einen Engpass in den überwachten Anwendungen darstellen kann, muss das Protokollieren des IOs mit möglichst geringem Aufwand an Speicher und Laufzeit erfolgen.

\subsubsection{POSIX über glibc}
\label{subsubsec:posix_ueber_glibc}

Die POSIX Implementierung in Linux stellt Systemfunktionen entsprechend der einzelnen POSIX-Funktionen bereit. Diese werden meist nicht direkt, sondern über die entsprechende c-Bibliothek glibc aufgerufen\cite{man.intro2}. Für die Fälle, in denen die Systemfunktionen über glibc aufgerufen werden, können Wrapper für die einzelnen Funktionen bereitgestellt werden.

Dabei ist zu beachten, dass einige Funktionen innerhalb der glibc wiederum andere Funktionen aufrufen. So ruft beispielsweise ,,printf`` zunächst ,,puts`` auf. In ,,puts`` wird wiederum ,,write`` aufgerufen. Da mit den folgend beschriebenen Mitteln nur Aufrufe von außen an die glibc-Bibliothek gewrappt werden können, Aufrufe innerhalb von glibc aber nicht, müssen für das Wrappen aller ,,write``-Aufrufe auch ,,puts`` und ,,printf`` gewrappt werden.

Die folgenden Vorgehensweisen setzen voraus, dass die glibc genutzt wird. Dies ist abhängig von der genauen Implementierung des jeweiligen Programms. Es gibt Programme, welche direkt die Systemfunktionen aufrufen ohne die glibc zu verwenden.

\paragraph{Dynamische gelinkt:}
\label{par:dynamisch_gelinkt}

Unter Linux existiert die Umgebungsvariable ,,LD\_PRELOAD``. Diese kann zur Angabe eines Pfades zu einer shared library genutzt werden. Die entsprechend über diesen Pfad angegebene Bibliothek wird dann vor allen anderen Bibliotheken geladen. Werden in dieser Bibliothek Funktionen der glibc-Bibliothek (C-Interface zu Systemfunktionen unter Linux)\cite{man.syscalls2} überschrieben, so werden anstelle der glibc-Funktionen die überschriebenen Funktionen ausgeführt.

Um innerhalb der überschriebenen Funktionen die ursprünglich gerufene Funktion aus der glibc-Bibliothek aufzurufen, kann nicht direkt der Funktionsname genutzt werden, da dies zu einem Namenskonflikt mit der überschriebenen Funktion führt. Anstelle eines Aufrufs über den Namen kann allerdings mit der Funktion dlsym\cite{man.dlsym3} die Adresse der gewünschten Funktion ermittelt werden. Über diese Adresse kann dann die Funktion in glibc ausgeführt werden.

Die Funktion dlsym muss mit der Konstante ,,RTLD\_NEXT`` (findet erste Routine innerhalb der geladenen Module) aufgerufen werden. Aus Performancegründen muss dabei über einen Init Hook (Linker -init) sichergestellt sein, dass einmalig nach dem Laden von glibc der jeweilige Funktionspointer ermittelt wird.

Ein Beispiel für einen dynamischen Wrapper kann dem Anhang entnommen werden \verw{sec:dynamischer_wrapper_mit_zentraler_buffer}.

\paragraph{Statisch gelinkt:}
\label{par:statisch_gelinkt}

Werden Funktionen nicht zur Laufzeit dynamisch ermittelt, sondern sind statisch fest eingebunden, so kann ein Wrapper nur zum Zeitpunkt des Linkens eingebunden werden. Hierfür kann im GNU Linker die Option ,,ld --wrap=symbol`` \cite{man.ld1} genutzt werden. Über den gcc kann die Option ,,-Wl``genutzt werden, damit intern der Linker mit ,,ld --wrap`` aufgerufen wird.

Ein Beispiel für einen statischen Wrapper \verw{sec:statischer_wrapper} und einen dazu passenden Aufruf des Linkers \verw{sec:linken_statischer_wrapper} kann dem Anhang entnommen werden.

\subsubsection{POSIX über Kernel Entry Point}
\label{subsubsec:posix_ueber_kernel_entry_point}

Im Projekt vorerst nicht relevant, da üblicherweise über glibc und nicht direkt über System Calls mittels Kernel Entry Point gearbeitet wird. Sollte der Projektfokus entsprechend erweitert werden, so sind die Wrapper \verw{subsec:architektur_wrapper} nicht ausreichend. Ansätze für mögliche Lösungen können dem Linux-Programm ptrace oder Programmen wie Plash, Systrace, Subterfugue, Chrome sandbox und Pink trace entnommen werden. Ein möglicher Ansatz ist ,,system call interposition``. Dieser Ansatz macht aber eventuell bei jedem System Call einen zusätzlichen Kontextwechsel notwendig und wirkt sich damit stark auf die Performance aus.

\subsubsection{Thread Local Storage}
\label{subsubsec:thread_local_storage}

Über Thread Local Storage (TLS) sicherstellen, dass beim Schreiben in den Speicher keine Synchronisation notwendig ist und somit auch keine Wartezeiten anfallen. Im TLS für jeden Thread einer Anwendung einen Buffer zum Schreiben reservieren. Sobald ein Buffer voll ist, die enthaltenen Daten in eine eigene Datei schreiben. Dabei die Prozess-ID und die Thread-Nummer im Dateinamen vermerken. Auf diese Weise ist auch beim Schreiben in die Datei keine Synchronisation notwendig.

Um den TLS beim Start eines Threads zu reservieren und ihn vor dem Ende des jeweiligen Threads abschließend in eine Datei zu übernehmen, muss das Starten und das Beenden eines Threads erkannt werden. Zusätzlich zum Reservieren und Leeren des TLS muss auch das Öffnen und Schließen der jeweiligen Datei abhängig von der Laufzeit des jeweiligen Threads erfolgen \verwb{fig:sequenzdiagramm_wrapper_mit_tls}.

Da die Funktionalität zum Überprüfen, ob der Buffer noch ausreichend leeren Platz enthält, und zum Leeren des Buffers in eine Datei, in jedem Wrapper einer POSIX-/MPI-IO-Funktion benötigt wird, muss sie in separate Funktionen ausgelagert werden. Dabei kann die Funktion zum Prüfen des Buffers die Funktion zum Leeren intern nutzen/aufrufen. Somit muss in den Wrappern nur eine Funktion genutzt werden und das Leeren steht dennoch als separate Funktion für das Beenden eines Threads zur Verfügung.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=latex]
\draw[black] (0,0) node[above] {Programm} -- (0,-0.5);
\draw[black,fill=black!20] (-0.2,-0.5) rectangle (0.2,-13);
\draw[->,black] (-0.7,-0.5) -- (-0.2,-0.5);
\draw[->,black] (-0.2,-13) -- (-0.7,-13);
\draw[black] (0,-13) -- (0,-13.5);

\draw[black] (4,0) node[above] {IOInfolib} -- (4,-1);
\draw[black,fill=black!20] (3.8,-1) rectangle (4.2,-3.5);
\draw[->,black] (0.2,-1) -- node[fill=white] {startThread()} (3.8,-1);
\draw[->,black] (4.2,-1.5) -- (4.7,-1.5) -- node[right] {TLS initialisieren} (4.7,-2) -- (4.2,-2);
\draw[->,black] (3.8,-3.5) -- (0.2,-3.5);
\draw[black] (4,-3.5) -- (4,-4);
\draw[->,black] (0.2,-4) -- node[fill=white] {fileIO()} (3.8,-4);
\draw[black,fill=black!20] (3.8,-4) rectangle (4.2,-9.5);
\draw[->,black] (4.2,-4.5) -- (4.7,-4.5) -- node[right] {TLS ausreichend?} (4.7,-5) -- (4.2,-5);
\draw[->,black] (4.2,-7.5) -- (4.7,-7.5) -- node[right] {log in TLS} (4.7,-8) -- (4.2,-8);
\draw[->,black] (3.8,-9.5) -- (0.2,-9.5);
\draw[black] (4,-9.5) -- (4,-10);
\draw[->,black] (0.2,-10) -- node[fill=white] {stopThread()} (3.8,-10);
\draw[black,fill=black!20] (3.8,-10) rectangle (4.2,-12.5);
\draw[->,black] (3.8,-12.5) -- (0.2,-12.5);
\draw[black] (4,-12.5) -- (4,-13.5);

\draw[black] (8,0) node[above] {glibc} -- (8,-2.5);
\draw[black,fill=black!20] (7.8,-2.5) rectangle (8.2,-3);
\draw[->,black] (4.2,-2.5) -- node[fill=white] {openLogFile()} (7.8,-2.5);
\draw[->,black] (7.8,-3) -- (4.2,-3);
\draw[black] (8,-3) -- (8,-6);
\draw[black,fill=black!20] (7.8,-6) rectangle (8.2,-6.5);
\draw[->,black] (4.2,-6) -- node[fill=white] {writeLogFile()} (7.8,-6);
\draw[->,black] (7.8,-6.5) -- (4.2,-6.5);
\draw[black] (8,-6.5) -- (8,-8.5);
\draw[black,fill=black!20] (7.8,-8.5) rectangle (8.2,-9);
\draw[->,black] (4.2,-8.5) -- node[fill=white] {fileIO()} (7.8,-8.5);
\draw[->,black] (7.8,-9) -- (4.2,-9);
\draw[black] (8,-9) -- (8,-10.5);
\draw[black,fill=black!20] (7.8,-10.5) rectangle (8.2,-11);
\draw[->,black] (4.2,-10.5) -- node[fill=white] {writeLogFile()} (7.8,-10.5);
\draw[->,black] (7.8,-11) -- (4.2,-11);
\draw[black] (8,-11) -- (8,-11.5);
\draw[black,fill=black!20] (7.8,-11.5) rectangle (8.2,-12);
\draw[->,black] (4.2,-11.5) -- node[fill=white] {closeLogFile()} (7.8,-11.5);
\draw[->,black] (7.8,-12) -- (4.2,-12);
\draw[black] (8,-12) -- (8,-13.5);

\draw[black] (-0.7,-5.5) -- node[below, at end] {TLS nicht ausreichend} (10.5,-5.5);
\draw[black] (-0.7,-7) -- (10.5,-7);
\end{tikzpicture}
\caption{Sequenzdiagramm Wrapper mit TLS}
\label{fig:sequenzdiagramm_wrapper_mit_tls}
\end{figure}

Je nach Art der Parallelisierung unter Linux kann das Starten und das Stoppen eines nebenläufigen Vorgangs unterschiedlich abgefangen werden. Bei einem Vorgehen über fork() und exit() werden separate Prozesse (heavy-weight process) gestartet. Geschieht dies über die entsprechenden Funktionen in der glibc, so kann es über Wrapper abgefangen werden. Zusätzlich müssen noch alle nicht mittels fork() sondern über einen Befehl zum Ausführen einer Datei gestarteten Prozesse abgefangen werden. Dies betrifft die Funktionen execl(), execlp(), execv() und execvp().
Wird anstelle von fork() die Funktion clone() genutzt, so wird kein Prozess, sondern ein Thread (light-weight process) gestartet. Daher muss diese Funktion ebenfalls abgefangen werden. In diesem Fall gibt es keinen exit() für die einzelnen Threads. Stattdessen kann ein waitpid() mit der Prozess-ID des Threads genutzt werden, um das Ende des Threads zu erkennen. In diesem Fall ist der Speicher des Threads allerdings bereits freigegeben und nicht mehr sicher nutzbar. Das finale Schreiben des Buffers in eine Datei kann also auf diesem Weg nicht ermöglicht werden. Das gleiche gilt für exit\_group(). Über diese Funktion werden mehrere laufende Prozesse/Threads in einer Prozess-Gruppe gemeinsam beendet. Auch hierbei kann nicht sichergestellt werden, ob der Speicher eines Threads bereits freigegeben wurde.

Wurde alternativ über die POSIX-Threads in der glibc parallelisiert, so kann über das Makro pthread\_cleanup\_push() eine weitere Funktion zum finalen Cleanup übergeben werden. Da dieses Makro allerdings immer mit einem weiteren Makro (pthread\_cleanup\_pop()) innerhalb der gleichen umschließenden Klammern kombiniert werden muss, lässt sich dieser Ansatz bei einer event-orientierten Vorgehensweise nicht nutzen. Zudem funktioniert dieses Vorgehen nur bei Threads, die mit den entsprechenden Funktionen der glibc erstellt wurden. Somit lassen sich beispielsweise über openMP parallelisierte Programme so nicht instrumentieren.

Bei dieser Architektur muss also zwischen unterschiedlichen Parallelisierungsarten unterschieden werden. Zudem gibt es Vorgehensweisen, die nicht über die glibc-Funktionen gehen. So nutzen manche Programmme direkt die Funktionen des Kernels und reduziert auf diese Weise den Overhead der Parallelisierung auf ein Minimum. Leider gibt es bei diesen Programmen somit keine Funktionen in der glibc oder einer anderen Bibliothek, die durch einen Wrapper abgefangen werden können.

Ein weiterer Nachteil dieser Architektur ist der erhöhte Speicherverbrauch. Um Verzögerungen durch dynamische Reservierung von Speicher (alloc() bzw. malloc()) zu vermeiden soll der benötigte Speicher einmalig reserviert werden. Beim dynamischen Reservieren müsste zum einen das Betriebssystem prüfen, ob und wenn ja wo der angefragte Speicherplatz verfügbar ist. Zum Anderen müssten Strategien für den Fall, dass nicht ausreichend Speicherplatz zur Laufzeit verfügbar ist, implementiert werden. Es findet daher kein nachträgliches Vergrößern des Speichers statt. Dies deckt sich mit den Anforderungen an TLS. Hier wird einmalig zum Start eines Threads der benötigte Speicher reserviert. Daraus ergibt sich allerdings das Problem, dass für jeden Thread bereits zum Start des Threads ein großer Buffer reserviert werden muss. Zu diesem Zeitpunkt steht noch nicht fest, wie viel File-IO der jeweilige Thread tatsächlich ausführt. Im Extremfall führt ein Thread überhaupt keinen File-IO aus und benötigt daher eigentlich keinen Buffer im TLS. Dies kann der jeweilige Wrapper zwar während der Ausführung des Threads analysieren und bei Beenden des Threads final feststellen, da die Reservierung des Speichers aber schon zum Start des Threads erfolgen muss, wird unnötigerweise Speicherplatz blockiert. Wird aufgrund dieses Umstandes ein kleiner Buffer gewählt, so wirkt sich dies negativ auf alle Threads aus, die tatsächlich viel File-IO ausführen. Bei diesen ist der kleine Buffer ständig voll und muss vor erneutem Protokollieren des IOs erst durch Schreiben in eine Datei geleert werden. Dies bremst den Thread aus und steht somit im Widerspruch zu den Anforderungen an die Wrapper-Architektur.

\subsubsection{Zentraler Buffer}
\label{subsubsec:zentraler_buffer}

Ein einziger zentraler Buffer umgeht die Probleme bei der Nutzung von TLS \verw{subsubsec:thread_local_storage}. Es ist keine Unterscheidung in verschiedene Arten der Parallelisierung und kein unnötiges Reservieren von Speicher notwendig \verwb{fig:sequenzdiagramm_wrapper_mit_zentralem_buffer}. Allerdings erfordert das Schreiben in den zentralen Buffer eine Synchronisation zwischen den einzelnen Threads einer Anwendung. Hierdurch entsteht ein Engpass, durch den sich Threads gegenseitig ausbremsen können. Daher ist diese Architekturvariante zwar leicht zu implementieren, verfehlt aber die Vorgabe möglichst performant zu sein.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=latex]
\draw[black] (0,-3) node[above] {Programm} -- (0,-3.5);
\draw[black,fill=black!20] (-0.2,-3.5) rectangle (0.2,-10);
\draw[->,black] (-0.7,-3.5) -- (-0.2,-3.5);
\draw[->,black] (-0.2,-10) -- (-0.7,-10);
\draw[black] (0,-10) -- (0,-10.5);

\draw[black] (3,-3) node[above] {IOInfolib} -- (3,-4);
\draw[->,black] (0.2,-4) -- node[fill=white] {fileIO()} (2.8,-4);
\draw[black,fill=black!20] (2.8,-4) rectangle (3.2,-9.5);
\draw[->,black] (3.2,-4.5) -- (3.7,-4.5) -- node[right] {Buffer ausreichend?} (3.7,-5) -- (3.2,-5);
\draw[->,black] (3.2,-7.5) -- (3.7,-7.5) -- node[right] {log in Buffer} (3.7,-8) -- (3.2,-8);
\draw[->,black] (2.8,-9.5) -- (0.2,-9.5);
\draw[black] (3,-9.5) -- (3,-10.5);

\draw[black] (7,-3) node[above] {glibc} -- (7,-6);
\draw[black,fill=black!20] (6.8,-6) rectangle (7.2,-6.5);
\draw[->,black] (3.2,-6) -- node[fill=white] {writeLogFile()} (6.8,-6);
\draw[->,black] (6.8,-6.5) -- (3.2,-6.5);
\draw[black] (7,-6.5) -- (7,-8.5);
\draw[black,fill=black!20] (6.8,-8.5) rectangle (7.2,-9);
\draw[->,black] (3.2,-8.5) -- node[fill=white] {fileIO()} (6.8,-8.5);
\draw[->,black] (6.8,-9) -- (3.2,-9);
\draw[black] (7,-9) -- (7,-10.5);

\draw[black] (-0.7,-5.5) -- node[below, at end] {Buffer nicht ausreichend} (9.5,-5.5);
\draw[black] (-0.7,-7) -- (9.5,-7);
\end{tikzpicture}
\caption{Sequenzdiagramm Wrapper mit zentralem Buffer}
\label{fig:sequenzdiagramm_wrapper_mit_zentralem_buffer}
\end{figure}

\subsubsection{Lock-free Bag}
\label{subsubsec:lock_free_bag}

Um die Vorteile der Architekturvarianten Thread Local Storage \verw{subsubsec:thread_local_storage} und zentraler Buffer \verw{subsubsec:zentraler_buffer} zu kombinieren und gleichzeitig die jeweiligen Nachteile zu vermeiden kann ein lock-free Bag genutzt werden. Dabei wird in einen zentralen Bag geschrieben \verwb{fig:sequenzdiagramm_wrapper_mit_lock_free_bag}. Es ist also nicht notwendig das Verwalten von Threads zu überwachen. Zur Synchronisation der Zugriffe nutzt der Bag atomare Instruktionen. Hierbei wird lediglich ein Pointer in den Bag atomar inkrementiert. Das Schreiben in den durch den Pointer definierten Speicherbereich erfolgt nach dem Inkrementieren unsynchronisiert. Somit wird die Synchronisation auf eine einzige Instruktion beschränkt. Sie ist somit auf das absolut mögliche Minimum reduziert. Hierfür muss die zugrunde liegende Architektur des Prozessors jedoch entsprechende atomare Instruktionen zur Inkrementierung eines Pointers anbieten. Diese Architekturvariante funktioniert daher nicht mit jedem Prozessor.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=latex]
\draw[black] (0,-3) node[above] {Programm} -- (0,-3.5);
\draw[black,fill=black!20] (-0.2,-3.5) rectangle (0.2,-10.5);
\draw[->,black] (-0.7,-3.5) -- (-0.2,-3.5);
\draw[->,black] (-0.2,-10.5) -- (-0.7,-10.5);
\draw[black] (0,-10.5) -- (0,-11);

\draw[black] (3,-3) node[above] {IOInfolib} -- (3,-4);
\draw[->,black] (0.2,-4) -- node[fill=white] {fileIO()} (2.8,-4);
\draw[black,fill=black!20] (2.8,-4) rectangle (3.2,-10);
\draw[->,black] (2.8,-10) -- (0.2,-10);
\draw[black] (3,-10) -- (3,-11);

\draw[black] (6,-3) node[above] {Bag} -- (6,-7);
\draw[black,fill=black!20] (5.8,-7) rectangle (6.2,-9.5);
\draw[->,black] (3.2,-7) -- node[fill=white] {log()} (5.8,-7);
\draw[->,black] (5.8,-9.5) -- (3.2,-9.5);
\draw[black] (6,-9.5) -- (6,-11);

\draw[black] (9,-3) node[above] {glibc} -- (9,-6);
\draw[black,fill=black!20] (8.8,-4.5) rectangle (9.2,-6);
\draw[->,black] (3.2,-4.5) -- node[fill=white] {fileIO()} (8.8,-4.5);
\draw[->,black] (8.8,-6) -- (3.2,-6);
\draw[black] (9,-6) -- (9,-7.5);
\draw[black,fill=white] (8.8,-7.5) rectangle (9.2,-9);
\draw[->,black,dashed] (6.2,-7.5) -- node[fill=white] {fileIO()} (8.8,-7.5);
\draw[->,black,dashed] (8.8,-9) -- (6.2,-9);
\draw[black] (9,-9) -- (9,-11);

\draw[black] (12,-3) node[above] {Kernel} -- (12,-5);
\draw[black,fill=black!20] (11.8,-5) rectangle (12.2,-5.5);
\draw[->,black] (9.2,-5) -- node[fill=white] {fileIO()} (11.8,-5);
\draw[->,black] (11.8,-5.5) -- (9.2,-5.5);
\draw[black] (12,-5.5) -- (12,-8);
\draw[black,fill=white] (11.8,-8) rectangle (12.2,-8.5);
\draw[->,black,dashed] (9.2,-8) -- node[fill=white] {fileIO()} (11.8,-8);
\draw[->,black,dashed] (11.8,-8.5) -- (9.2,-8.5);
\draw[black] (12,-8.5) -- (12,-11);
\end{tikzpicture}
\caption{Sequenzdiagramm Wrapper mit lock-free Bag}
\label{fig:sequenzdiagramm_wrapper_mit_lock_free_bag}
\end{figure}

\subsection{System}
\label{subsec:system}

Die libiotrace schaltet sich zwischen den Prozess und die glibc. Dadurch kann jeder Aufruf einer Funktion für File-IO an die glibc abgefangen und protokolliert werden. Die Protokollierung erfolgt in einem JSON-File. Jeder mittels libiotrace überwachte Prozess führt somit pro Ausführung zu einer Datei mit Daten im JSON-Format \verwb{fig:systemarchitektur}. Das Ablegen der Rohdaten in Dateien hat mehrere Gründe. Zum einen wird der überwachte Prozess nicht noch zusätzlich durch eine Analyse der Daten ausgebremst. Zum anderen stehen die Daten für die Analyse durch verschiedene Anwendungen zur Verfügung. Es können neue Anwendungen auf Basis der Dateien erstellt werden, ohne dass hierfür die libiotrace angepasst oder aus der neuen Anwendung mit der libiotrace kommuniziert werden muss.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=latex]

\node(Prozess) {Prozess};
\node[draw,fill=white,below of=Prozess] (Thread1) {Thread};
\node[draw,fill=white,below of=Thread1] (Thread2) {Thread};
\node[draw,fill=white,right of=Thread1,xshift=1cm] (IOTrace) {IOTrace};
%\draw [->] (Prozess) -- (IOTrace);
\draw [->] (Thread1) -- (IOTrace);
\draw [->] (Thread2) -- (IOTrace);
\begin{scope}[on background layer]
\node[fit=(Prozess)(Thread1)(Thread2)(IOTrace), draw,fill=black!20](Prozess_Rahmen){};
\end{scope}

\node[draw,right of=IOTrace,xshift=1.5cm] (JSON-File) {JSON-File};
\draw [->] (IOTrace) -- (JSON-File);

\node[draw,fill=white,right of=JSON-File,xshift=1.5cm] (Script) {Script};
\draw [->] (JSON-File) -- (Script);
\node[draw,fill=white,right of=Script,xshift=0.5cm] (DB) {DB};
\draw [->] (Script) -- (DB);
\node[draw,fill=white,right of=DB,xshift=1cm] (Analyselogik) {Analyselogik};
\draw [->] (DB) -- (Analyselogik);
\node[draw,fill=white,right of=Analyselogik,xshift=2cm] (Webclient1) {Webclient};
\node[draw,fill=white,below of=Webclient1] (Webclient2) {Webclient};
\draw [->] (Analyselogik) -- (Webclient1);
\draw [->] (Analyselogik) -- (Webclient2);
\node[above of=Script] (Analyse) {Analyse};
\begin{scope}[on background layer]
\node[fit=(Script)(DB)(Analyselogik)(Webclient1)(Webclient2)(Analyse), draw,fill=black!20](IO-Analyse_Rahmen){};
\end{scope}

\end{tikzpicture}
\caption{Systemarchitektur}
\label{fig:systemarchitektur}
\end{figure}

Ein überwachter Prozess kann, abhängig vom jeweiligen File-IO, sehr viele Protokolldaten erzeugen. Um in diesen die zur Analyse und Visualisierung interessanten Konstellationen zu finden, müssen sie performant durchsucht werden können. Sollen zudem die Protokolle mehrerer Prozesse in Abhängigkeit zueinander durchsucht werden, so wird die Datenmenge und somit das Problem größer. Für eine performante Verarbeitung der Protokolldaten muss daher eine schnelle Suche in den Daten möglich sein. Hierfür werden die einzelnen Protokolldateien über ein Script in eine Datenbank importiert. Die Datenbank stellt über die Generierung von Indizes performante Suchen zur Verfügung.

Um verschiedenen Frontends über die gleiche Datenbank versorgen zu können, ohne hierbei für jedes Frontend erneut grundlegende Analysefunktionen zu implementieren, werden Analysen in eine eigene Komponente ausgelagert. Diese Komponente regelt die Datenbankverbindung und bietet Schnittstellen für die Frontends an. Über die Schnittstelle können interaktiv sowohl die Rohdaten, als auch Analyseergebnisse abgefragt werden.

Die Visualisierung der Daten und Analysen erfolgt in den Frontends. Hier wird zunächst ein Webfrontend vorgesehen. Dieses ermöglicht eine Visualisierung unabhängig vom genutzten Client.

\section{Umsetzung}
\label{sec:umsetz}

Vor der Implementierung von Analysen und der Visualisierung der Ergebnisse müssen die Wrapper zum Protokollieren der benötigten Daten vorhanden sein. Daher werden zunächst die Wrapper entwickelt.

\subsection{Wrapper}
\label{subsec:umsetzung_wrapper}

Die benötigten Wrapper und alle zum Protokollieren in eine Datei benötigten Funktionen werden in einer Bibliothek zusammengefasst bereitgestellt. Diese Bibliothek heißt libiotrace. Sie wird in einer Variante für dynamisch gelinkte Programme und einer Variante zum statischen Linken bereitgestellt.

Die Umsetzung der libiotrace erfolgt aus Performancegründen in der Programmiersprache C. Dabei wird CMake als Buildtool genutzt. Somit kann die Entwicklung der Bibliothek möglichst portabel gehalten werden. Für das Schreiben in die Protokolldatei müssen parallele Prozesse unterstützt werden. Dies macht eine threadsafe Implementierung der Bibliothek notwendig. Aus Performancegründen ist dabei eine Synchronisation über Locks unerwünscht. Stattdessen erfolgt die Umsetzung über hochperformante und möglichst lockfreie Datenstrukturen.

Die Entwicklung erfolgt in einer frei verfügbaren und kostenlosen IDE mit Unterstützung für die Sprache C. Neben Netbeans kommt somit auch Eclipse in Frage. Aufgrund des Einsatzes von CMake kann die IDE beliebig gewechselt werden. Sofern die IDE CMake-Projekte nicht direkt unterstützt erfolgt die Entwicklung zwar in der IDE, der Buildvorgang wird dann aber außerhalb der IDE durchgeführt.

Für die gemeinsame Entwicklung und die Verwaltung unterschiedlicher Entwicklungsstände wird ein Repository-System benötigt. Dieses muss wie die IDE frei verfügbar und kostenlos sein. Entsprechend der aktuellen Verbreitung und Popularität wurde hierfür GIT ausgewählt. Das Projektrepository ist unter \url{https://github.com/hpcraink/fsprj2} erreichbar.

Um Unit-Tests zu ermöglichen wird das Projekt CUnit genutzt \cite{git.gitlab}.

\subsection{Framework}
\label{subsec:umsetzung_framework}

Zur Erstellung der Wrapper wurde ein Framework entworfen und umgesetzt. Dieses stellt für die generelle Funktionsweise der Wrapper benötigte Logik in Form von Funktionen und Makros zur Verfügung. Auf diese Weise muss in den Wrappern lediglich die für einen Wrapper spezifische Logik implementiert werden, während generelle (für alle Wrapper benötigte) Funktionsweisen aus dem Framework bezogen werden. Über das Framework werden so beispielsweise alle zum wahlweise statischen oder dynamischen Linken benötigten Sourcecodeanpassungen gesteuert.

\subsubsection{Header-Makros}
\label{subsubsec:header_makros}

Für jeden Wrapper wird zunächst ein Eintrag in einer zugehörigen Header-Datei benötigt. Über diesen wird die zum Linken benötigte Signatur der zu wrappenden Funktion definiert. Dies hat für statisches \verw{par:statisch_gelinkt} und dynamisches \verw{par:dynamisch_gelinkt} Linken auf verschiedene Weise zu erfolgen. Hierfür stellt das Framework sechs Makros zur Verfügung. Diese werden im Folgenden anhand der POSIX Funktion close() erläutert.

\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_h.txt}

Die Makros REAL\_TYPE, REAL() und REAL\_INIT definieren die Signatur der Funktion. Für statisches Linken wird dabei lediglich der Funktionsnamen um den Prefix \_\_real\_ ergänzt. Dies ist notwendig, um beim Linken die Namenskonventionen der Option -wrap des Linkers zu erfüllen. Für dynamisches Linken wird anstelle einer einfachen Funktionsdeklaration ein statischer Funktionspointer erstellt und mit NULL initialisert. Die unterschiedliche Auflösung der Makros für statisches beziehungsweise dynamisches Linken geschieht anhand des per CMake gesetzten Makros IO\_LIB\_STATIC.

Für den Funktionspointer zum dynamischen Linken zur Laufzeit wird noch zusätzlich die Startadresse der zu wrappenden Funktion ermittelt. Dies geschieht abhängig davon, ob das Makro IO\_LIB\_STATIC nicht gesetzt ist. Nur in diesem Fall wird dynamisch gelinkt und somit der Pointer zur Laufzeit benötigt. Das Ermitteln der Adresse geschieht über eine eigene im Header definierte Funktion welche mittels des Makros ATTRIBUTE\_CONSTRUCTOR zunächst nur deklariert wird. Dieses Makro stellt, abhängig vom jeweiligen Compiler, ein Attribut zur Verfügung welches die Funktion einmalig beim Start des Programms ausführt. Somit wird der Pointer einmal ermittelt und dann für spätere Aufrufe der gewrappten Funktion bereitgehalten. Auf die Deklaration folgt die Definition. In dieser wird die Adresse mittels des Makros DLSYM ermittelt. Wenn in einer Header-Datei mehrere Wrapper deklariert werden sollen, so müssen hierfür nicht mehrere Funktionen zum Ermitteln der Adressen geschaffen werden. Es kann für alle Wrapper die gleiche Funktion genutzt werden, indem mehrere Aufrufe des Makros DLSYM in ihr eingefügt werden.

Beispiel für aufgelöste Makros zum statischen Linken:
\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_h_macro_static.txt}
Beispiel für aufgelöste Makros zum dynamischen Linken:
\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_h_macro_dynamic.txt}

Alle Makros für die Header-Dateien der Wrapper sind in wrapper\_defines.h definiert. Einzig IO\_LIB\_STATIC muss zusätzlich vor dem Kompilieren außerhalb der Source-Dateien gesetzt werden, wenn eine Wrapper-Bibliothek für das statische Linken erstellt werden soll. Dies kann zum Beispiel über CMake erfolgen.

\subsubsection{Wrapper-Makros und -Funktionen}
\label{subsubsec:wrapper_makros_und_Funktionen}

Passend zu jedem Eintrag in der Header-Datei muss in der zugehörigen C-Datei ein Wrapper existieren. Folgend ein Beispiel passend zum Beispiel für die Header-Datei \verw{subsubsec:header_makros} für die POSIX Funktion close().

\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_c.txt}

Das Makro WRAP dient zur passenden Benennung des Wrappers. Wie in der Header-Datei ist diese für statisches und dynamisches Linken unterschiedlich.

Beispiel für aufgelöstes Makro WRAP für statisches Linken:
\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_c_macro_static.txt}

Beispiel für aufgelöstes Makro WRAP für dynamisches Linken:
\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_c_macro_dynamic.txt}

Innerhalb des Wrappers werden zunächst die im Wrapper benötigten lokalen Variablen und Datenstrukturen definiert. Hierzu gehört insbesondere eine Variable zur Speicherung des Rückgabewertes der gewrappten Funktion (im Beispiel Variable mit der Bezeichnung ret) und Strukturen für die zu protokollierenden Daten. Damit die Strukturen automatisch in interne Buffer des Frameworks übernommen und in JSON-Strings serialisiert werden können, müssen sie über speizelle Makros erstellt worden sein \verw{subsubsec:struktur_makros}. Für die Grundlegende Funktion des Frameworks wird die Struktur basic zwingend benötigt. In ihr werden Hostname, Prozess-ID, Thread-ID, Funktionsname der gewrappten Funktion, Start- und Endezeitpunkt des Aufrufs der gewrappten Funktion, Fehlerstatus (im Fehlerfall mit genauer Beschreibung des Fehlers), Art des Dateizugriffs (Descriptor, Stream oder Memory) mit ID des Zugriffs und weitere Funktionsspezifische Strukturen gespeichert. Sofern das Framework künftig Wrapper ohne diese grundlegenden Daten unterstützen soll, müssen die Makros CALL\_\-REAL\_\-FUNCTION, CALL\_\-REAL\_\-FUNCTION\_\-RET und WRAP\_\-END angepasst bzw. durch alternative Makros mit weniger Funktionalität ersetzt/ergänzt werden, da in diesen aktuell die Struktur basic befüllt wird.

Nach den lokal benötigten Variablen/Strukturen muss als erstes das Makro WRAP\_START aufgerufen werden. Dieses Makro bekommt als Parameter den Namen der Struktur basic übergeben und dient zur Initialisierung der Wrapperfunktionalität. Aktuell wird hierbei nur eine Variable zur Sicherung des Inhaltes von errno angelegt und mit dem aktuellen Wert aus errno befüllt. Dies ist notwendig, damit der ursprünglich im überwachten Programm gesetzte Wert beim Aufruf der gewrappten Funktion wieder hergestellt werden kann (siehe Makros CALL\_\-REAL\_\-FUNCTION und CALL\_\-REAL\_\-FUNCTION\_\-RET). Sollte eine gewrappte Funktion den im überwachten Programm gesetzten Wert aus errno überprüfen/verarbeiten, so wird diese Logik nicht durch den Wrapper und dessen Funktionsaufrufe beeinträchtigt. Dieses Verhalten wird für Funktionen aus der glibc nicht benötigt, könnte aber bei künftigen Einsatzgebieten des Frameworks notwendig sein (wenn beispielsweise Funktionen zum Fehlerhandling in einem Programm gewrappt und überwacht werden sollen). Durch die Übergabe der Struktur basic kann das Makro WRAP\_START künftig um weiter Funktionen erweiter werden. Hierzu kann beispielsweise das Protokollieren des Zeitaufwands der Wrapperfunktion gehören.

Nach dem Aufruf von WRAP\_START werden die Datenstrukturen initial befüllt. Hierfür werden alle Daten, welche vor dem Aufruf der gewrappten Funktion verfügbar sind in die Datenstrukturen übernommen. Die Funktion get\_basic() wird hierfür vom Framework bereitgestellt, um den Hostnamen, die Prozess-ID und die Thread-ID zur ermitteln. Sie greift dabei auf zentral vom Framework pro Prozess und pro Thread angelegten Speicher zurück, um die benötigten Werte nur je einmal über Systemfunktionen zu ermitteln und in diesem Speicher für weitere Zugriffe zu hinterlegen. Für das Einbinden von Strukturen in andere Strukturen kann beim Erstellen einer Struktur das Makro JSON\_\-STRUCT\_\-VOID\_\-P\_\-START genutzt werden \verw{subsubsec:struktur_makros}. Dieses erstellt einen Pointer, welcher auf verschiedene Strukturen zeigen kann. Zusätzlich wird eine Enumeration erstellt, die angibt, welche Struktur tatsächlich im Pointer hinterlegt ist. Für die korrektet Verarbeitung durch das Framework muss die Enumeration immer passend zur im Pointer hinterlegten Struktur gesetzt sein. Dafür stellt das Framework zwei Makros zur Verfügung. Mittels JSON\_\-STRUCT\_\-SET\_\-VOID\_\-P\_\-NULL kann der Pointer mit NULL befüllt werden. Dementsprechend wird keine Struktur in interne Buffer übernommen und kein entsprechendes Element im JSON erzeugt. Im Beispiel ist dies für das Feld function\_data in der Struktur basic der Fall. Mit JSON\_\-STRUCT\_\-SET\_\-VOID\_\-P kann dagegen eine Struktur zusammen mit dem passenden Eintrag in der Enumeration erzeugt werden. Dies ist im Beispiel für das Feld file\_type in der Struktur basic der Fall. Hier wird die Struktur file\_descriptor\_data vom Typ file\_descriptor dem Pointer zugewiesen. Als weiteres Makro steht mit POSIX\_\-IO\_\-SET\_\-FUNCTION\_\-NAME eine Funktionalität zum Ermitteln des Funktionsnamens der gewrappten Funktion zur Verfügung. Als Parameter bekommt dieses Makro den Speicherplatz übergeben, an den der Funktionsname kopiert wird.

Nachdem die Strukturen initial befüllt sind, wird die gewrappte Funktion aufgerufen. Dies geschieht mit dem Makro CALL\_\-REAL\_\-FUNCTION\_\-RET oder dem Makro CALL\_\-REAL\_\-FUNCTION. Diese beiden Makros unterscheiden sich lediglich darin, dass CALL\_\-REAL\_\-FUNCTION\_\-RET den Rückgabewert der aufgerufenen Funktion zurückgibt und CALL\_\-REAL\_\-FUNCTION dies nicht tut. Als Parameter erwarten die Makros als ersten Wert den Namen der Struktur basic. Dieser wird für die Protokollierung des Start- und Endezeitpunktes des Funktionsaufrufes genutzt. Darauf folgt für CALL\_\-REAL\_\-FUNCTION\_\-RET der Name der Variable in die der Rückgabewert geschrieben wird. Darauf folgt der Name der Funktion und die Parameter der Funktion in der von der Funktion erwarteten Reihenfolge. Die beiden Makros sorgen zusätzlich zur Protokollierung der Zeit auch noch für das Rücksichern des im Makro WRAP\_START gesicherten Wertes von errno vor dem Funktionsaufruf und das Sichern desselben nach dem Funktionsaufruf.

Auf den Funktionsaufruf folgt das Sichern aller jetzt verfügbaren Werte, wie zum Beispiel des Rückgabewertes, in die Datenstrukturen.

Darauf folgt ein Aufruf des Makros WRAP\_END. Dieses prüft anhand des Feldes file\_type aus der Struktur basic, ob der Funktionsaufruf tatsächlich protokolliert werden soll. Dies geschieht, um Eingaben über den Standard Input-Kanal (stdin) und Ausgaben über den Standard Output-Kanal (stdout) und über den Standard Error-Kanal (stderr) nicht zu protokollieren. Soll der Aufruf protokolliert werden, so wird im Makro die Funktion writeData() aufgerufen. An diese wird die Struktur basic übergeben. Durch diese Übergabe erfolgt das Kopieren der Struktur (inklusive aller über Pointer in ihr referenzierten Strukturen) in einen frameworkinternen Buffer. Die im Wrapper genutzten Strukturen können dementsprechend nach dem Aufruf von WRAP\_END geändert oder gelöscht werden, ohne das dies Auswirkungen auf die Protokollierung hat. Die Prüfung, ob protokolliert werden soll, ist spezifisch für die Datenstruktur basic und damit für das Wrappen von File-IO-Funktionen. Sollen mit dem Framework andere Funktionen gewrappt werden, so muss das Makro WRAP\_END entsprechend angepasst oder durch ein Makro mit weniger Funktionalität ersetzt werden. Am Ende des Makros WRAP\_END wird der beim Aufruf der gewrappten Funktion im Makro CALL\_\-REAL\_\-FUNCTION bzw. im Makro CALL\_\-REAL\_\-FUNCTION\_\-RET gesicherte Wert von errno wieder hergestellt. Daher darf nach Aufruf von WRAP\_END keine Funktion aufgerufen werden, die errno erneut verändern kann, bevor ein Return aus dem Wrapper erfolgt.

Am Ende des Wrappers erfolgt ein Return mit einem eventuell zuvor gesicherten Rückgabewerte an das überwachte Programm.

Die Makros für die Wrapper in den C-Dateien stammen aus wrapper\_defines.h. Die Funktionen sind in event.h definiert. Für die zum Protokollieren genutzten Datenstrukturen muss zudem die Datei json\_include\_struct.h eingebunden werden \verw{subsubsec:struktur_makros}.

\subsubsection{Struktur-Makros}
\label{subsubsec:struktur_makros}

Strukturen, welche im Framework durch die Wrapper zum Protokollieren von Daten genutzt werden, müssen über spezielle Makros definiert sein \verw{subsubsec:wrapper_makros_und_Funktionen}. Diese Makros werden vom Framework in der Datei json\_defines.h bereitgestellt. Je nachdem wie diese Datei inkludiert wird, erstellen die Makros unterschiedlichen Source-Code. Wird vor einem Include das Makro JSON\_STRUCT passend gesetzt, so werden in json\_defines.h die gleichen Makros unterschiedlich definiert:

\begin{itemize}
  \item JSON\_STRUCT undefiniert: stellt die Makros JSON\_\-STRUCT\_\-DATA\_\-TYPE, JSON\_\-STRUCT\_\-PRINT, JSON\_\-STRUCT\_\-BYTES\_\-COUNT, JSON\_\-STRUCT\_\-SIZEOF und JSON\_\-STRUCT\_\-COPY zur Verfügung
  \item \#define JSON\_STRUCT JSON\_\-STRUCT\_\-DATA\_\-TYPE: Makros erstellen Strukturen
  \item \#define JSON\_STRUCT JSON\_\-STRUCT\_\-PRINT: Makros erstellen je Struktur eine Funktion zum Serialisieren der Struktur in einen JSON-String
  \item \#define JSON\_STRUCT JSON\_\-STRUCT\_\-BYTES\_\-COUNT: Makros erstellen je Struktur eine Funktion zum Ermitteln der maximalen Länge des JSON-Strings der Struktur
  \item \#define JSON\_STRUCT JSON\_\-STRUCT\_\-SIZEOF: Makros erstellen je Struktur eine Funktion zum Ermitteln der in der Struktur tatsächlich genutzten Bytes (ungenutzte Bytes in C-Strings werden nicht mitgezählt; über Pointer eingebundene Strukturen werden mitgezählt)
  \item \#define JSON\_STRUCT JSON\_\-STRUCT\_\-COPY: Makros erstellen je Struktur eine Funktion zum Kopieren der genutzten Bytes einer Struktur (siehe JSON\_\-STRUCT\_\-SIZEOF)
\end{itemize}

Die Makros aus json\_defines.h werden in json\_structs.h genutzt um alle benötigten Datenstrukturen zu definieren. In json\_include\_struct.h wird json\_structs.h einmal mit JSON\_STRUCT definiert als JSON\_STRUCT JSON\_\-STRUCT\_\-DATA\_\-TYPE inkludiert. Somit stehen in json\_include\_struct.h die benötigten Datenstrukturen zur Verfügung. In json\_include\_function.h wird json\_structs.h viermal inkludiert. Bei jedem Inkludieren wird das Makro JSON\_STRUCT anders gesetzt, so dass anschließend in json\_include\_function.h alle Funktionen zum Verarbeiten der Strukturen verfügbar sind. \verwb{fig:include_hierarchie_datenstrukturen}

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=latex, node distance=0.5cm, scale=0.75, every node/.style={scale=0.75}]
  \node (defines) {json\_defines.h};
  \node (JSON_STRUCT_DATA_TYPE) [draw, blue, below=of defines] {JSON\_STRUCT\_DATA\_TYPE};
  \node (JSON_STRUCT_PRINT) [draw, blue, below=of JSON_STRUCT_DATA_TYPE] {JSON\_STRUCT\_PRINT};
  \node (JSON_STRUCT_BYTES_COUNT) [draw, blue, below=of JSON_STRUCT_PRINT] {JSON\_STRUCT\_BYTES\_COUNT};
  \node (JSON_STRUCT_SIZEOF) [draw, blue, below=of JSON_STRUCT_BYTES_COUNT] {JSON\_STRUCT\_SIZEOF};
  \node (JSON_STRUCT_COPY) [draw, blue, below=of JSON_STRUCT_SIZEOF] {JSON\_STRUCT\_COPY};
  
  \node[fit=(defines)(JSON_STRUCT_DATA_TYPE)(JSON_STRUCT_PRINT)(JSON_STRUCT_BYTES_COUNT)(JSON_STRUCT_SIZEOF)(JSON_STRUCT_COPY), draw, scale=1.3](json_defines){};
  
  \node (structs) [left=of defines, xshift=-2cm] {json\_structs.h};
  \draw (-7,0.4) rectangle (-4.1,-6.9);
  
  \node (struct) [draw, left=of JSON_STRUCT_DATA_TYPE, xshift=-4cm] {json\_include\_struct.h};
  \node (function) [draw, below=of struct] {json\_include\_function.h};
  
  \draw [->] (JSON_STRUCT_DATA_TYPE) edge (struct);
  \draw [->] (JSON_STRUCT_PRINT) edge (function);
  \draw [->] (JSON_STRUCT_BYTES_COUNT) edge (function);
  \draw [->] (JSON_STRUCT_SIZEOF) edge (function);
  \draw [->] (JSON_STRUCT_COPY) edge (function);
\end{tikzpicture}
\caption{Include-Hierarchie Datenstrukturen}
\label{fig:include_hierarchie_datenstrukturen}
\end{figure}

\paragraph{Struktur}
\label{par:struktur}

Die Definition einer Struktur erfolgt über die Makros JSON\_\-STRUCT\_\-START und JSON\_\-STRUCT\_\-END. Nach JSON\_\-STRUCT\_\-START folgt in Klammern eingeschlossen ein Bezeichner. Dieser heißt im Schaubild ,,name`` \verwb{fig:syntax_struktur}. Er muss den Konventionen der Programmiersprache C für einen Strukturnamen entsprechen. Die generierte Struktur bekommt diesen Bezeichner als Namen. Der Bezeichner steht nach dem Inkludieren von json\_include\_struct.h dementsprechend als Typnamen zur Deklaration lokaler Strukturen bereit. Zwischen den beiden Makros können beliebig viele, über weitere Makros definierte, Elemente stehen. Es ist insbesondere auch möglich eine Struktur ohne Elemente zu definieren.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_START"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ")"[terminal] -- p1 -- p2 -> "Struct-Element"[nonterminal] -- p3 -- p4 -- p5;

    p6[yshift=-5mm] -> "JSON\_STRUCT\_END"[terminal, yshift=-5mm] -> p7[yshift=-5mm];

    p5 --[skip loop=-7mm] p6;
    p1 ->[skip loop=5mm] p4;
    p3 ->[skip loop=-5mm] p2;
  };
\end{tikzpicture}
\caption{Syntax Struktur}
\label{fig:syntax_struktur}
\end{figure}

\paragraph{Struct-Element}
\label{par:struct_element}

Die unterschiedlichen Makros zur Definition verschiedener Elemente einer Struktur können in beliebiger Folge zwischen den Makros JSON\_\-STRUCT\_\-START und JSON\_\-STRUCT\_\-END genutzt werden \verwb{fig:syntax_struktur}. Die Makros der Elemente unterteilen sich in verschiedene Gruppen \verwb{fig:syntax_struct_element}.

Die erste Gruppe fügt zuvor über separate Makros erstellte Datentypen als Elemente in eine neue Struktur ein. Zu dieser Gruppe gehören die Makros JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD, JSON\_\-STRUCT\_\-ENUM, JSON\_\-STRUCT\_\-STRUCT und JSON\_\-STRUCT\_\-STRUCT\_\-P. Sie erstellen als Element ein Bitfield, eine Enumeration, eine Struktur oder einen Pointer auf eine andere Struktur. Jedes Makro dieser Gruppe bekommt zwei Parameter übergeben. Der erste ist der Name des über andere Makros erstellten Datentyps. Darauf folgt der Name, den das Datenelement in der neuen Struktur bekommt. Dieser Name wird beim Serialisieren auch als Elementname im JSON-Objekt genutzt.

Die größte Gruppe stellen die primitiven Datentypen dar. Zu jedem verfügbaren primitiven Datentyp existiert ein separates Makro. Dies sind JSON\_\-STRUCT\_\-CLOCK\_\-T, JSON\_\-STRUCT\_\-FD\_\-SET\_\-P, JSON\_\-STRUCT\_\-FILE\_\-P, JSON\_\-STRUCT\_\-INT, JSON\_\-STRUCT\_\-LONG\_\-INT, JSON\_\-STRUCT\_\-OFF\_\-T, JSON\_\-STRUCT\_\-PID\_\-T, JSON\_\-STRUCT\_\-SIZE\_\-T, JSON\_\-STRUCT\_\-SSIZE\_\-T, JSON\_\-STRUCT\_\-U\_\-INT64\_\-T und JSON\_\-STRUCT\_\-VOID\_\-P. Jedes Makro dieser Gruppe bekommt einen Parameter übergeben. Dieser ist der Name des Datenelements in der Struktur. Dieser Name wird beim Serialisieren auch als Elementname im JSON-Objekt genutzt.

Eine weitere Gruppe sind Arrays von primitiven Datentypen. Zu dieser Gruppe gehört aktuell nur das Makro JSON\_\-STRUCT\_\-CSTRING für Arrays des Datentyp char. Makros dieser Gruppe bekommen zwei Parameter übergeben. Der erste Parameter ist der Name des Datenelements in der Struktur. Dieser Name wird beim Serialisieren auch als Elementname im JSON-Objekt genutzt. Der zweiter Parameter ist die Länge des Arrays (für JSON\_\-STRUCT\_\-CSTRING inklusive des Endekennzeichens '\textbackslash{}0').

Eine weitere Gruppe sind Pointer auf Arrays primitiver Datentypen variabler Länge. Makros dieser Gruppe benötigen ein Endekennzeichen, welches anstelle eines Array-Elements stehen kann und ein Ende vor der maximalen Länge des Arrays anzeigt. Zu dieser Gruppe gehören aktuell nur die Makros JSON\_\-STRUCT\_\-CSTRING\_\-P und JSON\_\-STRUCT\_\-CSTRING\_\-P\_\-CONST (beide basieren auf dem Endekennzeichen für CStrings: '\textbackslash{}0'). Makros dieser Gruppe bekommen zwei Parameter übergeben. Wie bei einfachen Arrays (s.o.) ist der erste Parameter der Name des Elements in der Struktur. Der zweite gibt die maximale Länge des Arrays an.

Die letzte Gruppe ist für Unions. Sie enthält aktuell nur eine Union für Strukturen. Eine Union besteht aus mehreren Makros. Der genaue Aufbau wird in einem separaten Abschnitt erklärt \verw{par:struct_union}.

Beim Serialisieren als JSON-String werden Null-Pointer unterschiedlich behandelt. Bei den Makros JSON\_\-STRUCT\_\-VOID\_\-P und JSON\_\-STRUCT\_\-FILE\_\-P wird entsprechend der Konventionen der Funktion printf() ein String mit Inhalt ,,null`` erzeugt. Bei den Makros JSON\_\-STRUCT\_\-CSTRING\_\-P und JSON\_\-STRUCT\_\-CSTRING\_\-P\_\-CONST wird ein leerer String (,,``) erzeugt. Die Makros JSON\_\-STRUCT\_\-FD\_\-SET\_\-P, JSON\_\-STRUCT\_\-VOID\_\-P\_\-START \verw{par:struct_union} und JSON\_\-STRUCT\_\-STRUCT\_\-P erzeugen optionale JSON-Elemente, die bei einem Null-Pointer im JSON-String komplett entfallen.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -- p1 ->[vh path]
    {[nodes={yshift=7mm}]
      {[nodes={yshift=7mm}]
        "JSON\_STRUCT\_ARRAY\_BITFIELD"[terminal],
        "JSON\_STRUCT\_ENUM"[terminal],
        "JSON\_STRUCT\_STRUCT"[terminal],
        "JSON\_STRUCT\_STRUCT\_P"[terminal]
      } -> [hv path]
      p2 -> "("[terminal] -> "type"[nonterminal] -> ","[terminal] -> "name"[nonterminal] -> ")"[terminal],
      {[nodes={yshift=7mm}]
        "JSON\_STRUCT\_CLOCK\_T"[terminal],
        "JSON\_STRUCT\_FD\_SET\_P"[terminal],
        "JSON\_STRUCT\_FILE\_P"[terminal],
        "JSON\_STRUCT\_INT"[terminal],
        "JSON\_STRUCT\_LONG\_INT"[terminal],
        "JSON\_STRUCT\_OFF\_T"[terminal],
        "JSON\_STRUCT\_PID\_T"[terminal],
        "JSON\_STRUCT\_SIZE\_T"[terminal],
        "JSON\_STRUCT\_SSIZE\_T"[terminal],
        "JSON\_STRUCT\_U\_INT64\_T"[terminal],
        "JSON\_STRUCT\_VOID\_P"[terminal]
      } -> [hv path]
      p3 -> { [fresh nodes] "("[terminal] -> "name"[nonterminal] -> ")"[terminal] },
      "JSON\_STRUCT\_CSTRING"[terminal,yshift=7mm] -> { [fresh nodes] "("[terminal,yshift=7mm] -> "name"[nonterminal,yshift=7mm] -> ","[terminal,yshift=7mm] -> "length"[nonterminal,yshift=7mm] -> ")"[terminal,yshift=7mm] },
      {[nodes={yshift=7mm}]
      "JSON\_STRUCT\_CSTRING\_P"[terminal],
      "JSON\_STRUCT\_CSTRING\_P\_CONST"[terminal]
      } -> [hv path]
      p4 -> { [fresh nodes] "("[terminal] -> "name"[nonterminal] -> ","[terminal] -> "max\_length"[nonterminal] -> ")"[terminal] },
      "Struct-Union"[nonterminal,yshift=7mm]
    } -> [hv path]
    p5 ->/;

    % make these edges plain
    p1 -> "JSON\_STRUCT\_STRUCT";
    "JSON\_STRUCT\_ENUM" -- p2;
    "JSON\_STRUCT\_FD\_SET\_P" -- p3;
    "JSON\_STRUCT\_CSTRING\_P\_CONST" --p4;
  };
\end{tikzpicture}
\caption{Syntax Struct-Element}
\label{fig:syntax_struct_element}
\end{figure}

\paragraph{Struct-Union}
\label{par:struct_union}

Wenn in einer Struktur ein Pointer wahlweise auf verschiedene Strukturen zeigen soll, so kann dies mit den beiden Makros JSON\_\-STRUCT\_\-VOID\_\-P\_\-START und JSON\_\-STRUCT\_\-VOID\_\-P\_\-END erreicht werden \verwb{fig:syntax_struct_union}. Beide Makros müssen immer zusammen in der richtigen Reihenfolge genutzt werden. Zwischen ihnen müssen über weitere Makros die möglichen Strukturen für den Pointer definiert werden \verw{par:struct_union_element}. Dabei muss mindestens eine Struktur angegeben werden. Die beiden Makros bekommen je einen Parameter übergeben. Dieser Parameter ist der Name des Datenelements in der Struktur. Dieser Name wird beim Serialisieren auch als Elementname im JSON-Objekt genutzt. Bei jeder zusammengehörenden Folge der beiden Makros muss der Parameter identisch sein.

Beim Arbeiten mit einem über diese Makros erstellten Pointer müssen die Makros JSON\_\-STRUCT\_\-SET\_\-VOID\_\-P und JSON\_\-STRUCT\_\-SET\_\-VOID\_\-P\_\-NULL zum setzen des Pointers genutzt werden \verw{subsubsec:wrapper_makros_und_Funktionen}.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_VOID\_P\_START"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ")"[terminal] -- p2 -> "Struct-Union-Element"[nonterminal] -- p3 --p5;

    p6[yshift=-5mm] -> "JSON\_STRUCT\_VOID\_P\_END"[terminal,yshift=-5mm] -> { [fresh nodes] "("[terminal,yshift=-5mm] -> "name"[nonterminal,yshift=-5mm] -> ")"[terminal,yshift=-5mm] } -> p7[yshift=-5mm];

    p5 --[skip loop=-7mm] p6;
    p3 ->[skip loop=5mm] p2;
  };
\end{tikzpicture}
\caption{Syntax Struct-Union}
\label{fig:syntax_struct_union}
\end{figure}

\paragraph{Struct-Union-Element}
\label{par:struct_union_element}

Das Makro zum Definieren von möglichen Strukturen für den Strukturpointer der Makros JSON\_\-STRUCT\_\-VOID\_\-P\_\-START und JSON\_\-STRUCT\_\-VOID\_\-P\_\-END \verw{par:struct_union} hießt JSON\_\-STRUCT\_\-VOID\_\-P\_\-ELEMENT. Es bekommt zwei Parameter übergeben. Der erste ist der gleiche Name wie bei den umschließenden Makros JSON\_\-STRUCT\_\-VOID\_\-P\_\-START und JSON\_\-STRUCT\_\-VOID\_\-P\_\-END. Der zweite ist der Datentyp einer Struktur, die dem Pointer zugewiesen werden kann.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_VOID\_P\_ELEMENT"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ","[terminal] -> "element"[nonterminal] -> ")"[terminal] -> /;
  };
\end{tikzpicture}
\caption{Syntax Struct-Union-Element}
\label{fig:syntax_struct_union_element}
\end{figure}

\paragraph{Enumeration}
\label{par:enumeration}

Enumerations für die Verwendung mittels des Makros JSON\_\-STRUCT\_\-ENUM in Strukturen \verw{par:struct_element} müssen mit den folgenden drei Makros definiert sein \verwb{fig:syntax_enumeration}. Zu Beginn muss das Makro JSON\_\-STRUCT\_\-ENUM\_\-START stehen. Dieses bekommt als Parameter einen Namen für die Enumeration übergeben. Dieser Name steht dann als Datentyp zur Verfügung. Darauf folgt mindestens einmal das Makro JSON\_\-STRUCT\_\-ENUM\_\-ELEMENT \verw{par:enum_element} zur Definition einzelner Enum-Elemente und abschließend einmal das Makro JSON\_\-STRUCT\_\-ENUM\_\-END.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_ENUM\_START"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ")"[terminal] -- p2 -> "Enum-Element"[nonterminal] -- p3 --p5;

    p6[yshift=-5mm] -> "JSON\_STRUCT\_ENUM\_END"[terminal,yshift=-5mm] -> p7[yshift=-5mm];

    p5 --[skip loop=-7mm] p6;
    p3 ->[skip loop=-5mm] p2;
  };
\end{tikzpicture}
\caption{Syntax Enumeration}
\label{fig:syntax_enumeration}
\end{figure}

\paragraph{Enum-Element}
\label{par:enum_element}

Einzelne Enum-Elemente werden über das Makro JSON\_\-STRUCT\_\-ENUM\_\-ELEMENT definiert. Dieses bekommt als Parameter den Namen des Elements übergeben.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_ENUM\_ELEMENT"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ")"[terminal] -> /;
  };
\end{tikzpicture}
\caption{Syntax Enum-Element}
\label{fig:syntax_enum_element}
\end{figure}

\paragraph{Bitfield}
\label{par:bitfield}

Bitfields für die Verwendung mittels des Makros JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD in Strukturen \verw{par:struct_element} müssen mit den folgenden drei Makros definiert sein \verwb{fig:syntax_bitfield}. Zu Beginn muss das Makro JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD\_\-START stehen. Dieses bekommt als Parameter einen Namen für das Bitfield übergeben. Dieser Name steht dann als Datentyp zur Verfügung. Darauf folgt beliebig oft das Makro JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD\_\-ELEMENT \verw{par:bitfield_element} zur Definition einzelner Bitfield-Elemente und abschließend einmal das Makro JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD\_\-END.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_ARRAY\_BITFIELD\_START"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ")"[terminal] -- p5;

    p6[yshift=-5mm]  -- p1[yshift=-5mm] -- p2[yshift=-5mm] -> "Bitfield-Element"[nonterminal,yshift=-5mm] -- p3[yshift=-5mm] -- p4[yshift=-5mm] -> "JSON\_STRUCT\_ARRAY\_BITFIELD\_END"[terminal,yshift=-5mm] -> p7[yshift=-5mm];

    p5 --[skip loop=-5mm] p6;
    p1 ->[skip loop=5mm] p4;
    p3 ->[skip loop=-5mm] p2;
  };
\end{tikzpicture}
\caption{Syntax Bitfield}
\label{fig:syntax_bitfield}
\end{figure}

\paragraph{Bitfield-Element}
\label{par:bitfield_element}

Einzelne Bitfield-Elemente werden über das Makro JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD\_\-ELEMENT definiert. Dieses bekommt als Parameter den Namen des Elements übergeben.

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth, black!50, text=black, thick,
           every new ->/.style = {shorten >=1pt},
           graphs/every graph/.style = {edges=rounded corners},
           skip loop/.style = {to path={-- ++(0,#1) -| (\tikztotarget)}},
           hv path/.style = {to path={-| (\tikztotarget)}},
           vh path/.style = {to path={|- (\tikztotarget)}},
           nonterminal/.style = {
             rectangle, minimum size=6mm, very thick, draw=red!50!black!50, top color=white,
             bottom color=red!50!black!20, font=\itshape, text height=1.5ex,text depth=.25ex},
           terminal/.style = {
             rounded rectangle, minimum size=6mm, very thick, draw=black!50, top color=white,
             bottom color=black!20, font=\ttfamily, text height=1.5ex, text depth=.25ex},
           shape = coordinate
          ]
  \graph [grow right sep, branch down=7mm, simple] {
    / -> "JSON\_STRUCT\_ARRAY\_BITFIELD\_ELEMENT"[terminal] -> "("[terminal] -> "name"[nonterminal] -> ")"[terminal] -> /;
  };
\end{tikzpicture}
\caption{Syntax Bitfield-Element}
\label{fig:syntax_bitfield_element}
\end{figure}

\subsubsection{neue Makros für primitive Datentypen}
\label{subsubsec:neue_makros_fuer_primitive_datentypen}

Um einen noch nicht verfügbaren primitiven Datentypen für die automatisierte Verarbeitung durch das Framework bereitzustellen, muss die Datei json\_defines.h angepasst werden. In ihr gibt es sechs Stellen, an denen eine Zeile für den neuen Datentyp aufgenommen werden muss. Alle entsprechenden Stellen sind mit dem Kommentar \lstinline[language=C,numbers=left,numberstyle=\tiny]!/* insert new line for new data-type here */! gekennzeichnet.

Ist der primitive Datentyp ein Pointer, so ist besondere Vorsicht geboten. Soll die im Pointer enthaltene Adresse lediglich im JSON ausgegeben werden, so ist nichts weiter zu beachten. Verweist der Pointer dagegen auf Daten, die ebenfalls in den JSON-String übernommen werden sollen, so handelt es sich aus Sicht des Frameworks nicht um einen primitiven Datentypen. Die Makros können dann nicht wie hier dargestellt gestaltet werden. Stattdessen müssen sie ähnlich wie bei den Makros JSON\_\-STRUCT\_\-FD\_\-SET\_\-P, und JSON\_\-STRUCT\_\-CSTRING\_\-P oder gar wie in  JSON\_\-STRUCT\_\-ARRAY\_\-BITFIELD, JSON\_\-STRUCT\_\-ENUM, JSON\_\-STRUCT\_\-STRUCT und JSON\_\-STRUCT\_\-STRUCT\_\-P umgesetzt werden.

Folgend ein Beispiel für den primitiven Datentyp Integer. Im Beispiel sind nur die für Integer notwendigen Zeilen aus der json\_defines.h aufgeführt. Beim Einfügen neuer Datentypen in die json\_defines.h müssen diese sechs Zeilen jeweils vor dem entsprechenden Kommentar (s.o.) eingefügt werden. Nur wenn jede Zeile an der richtigen Position steht, ist die Funktionsweise der Makros gewährleistet \verw{subsubsec:struktur_makros}.
\begin{lstlisting}[language=C,numbers=left,numberstyle=\tiny]
#undef JSON_STRUCT_INT
#  define JSON_STRUCT_INT(name) int name;
#  define JSON_STRUCT_INT(name) JSON_STRUCT_ELEMENT(name, %d, json_struct_data->name)
#  define JSON_STRUCT_INT(name) JSON_STRUCT_ELEMENT_SIZE(name, JSON_STRUCT_TYPE_SIZE_DEC(int) + 1) /* +1 for sign (-) */
#  define JSON_STRUCT_INT(name)
#  define JSON_STRUCT_INT(name)
\end{lstlisting}
Die erste Zeile ermöglicht das mehrfache Importieren des Makros mit unterschiedlichen Definitionen. Dies ist für die Funktionsweise der Makros notwendig \verw{subsubsec:struktur_makros}. In der Zeile findet dementsprechend nur das Aufheben bisheriger Definitionen des Makros statt.

Die zweite Zeile wird beim Generieren der Strukturen genutzt. Dementsprechend muss diese Zeile ein Makro zur Erstellung einer Variablen des gewünschten primitiven Datentyps enthalten. Der Name der Variablen muss über den Parameter des Makros gesetzt werden.

Die dritte Zeile wird beim Serialisieren in einen JSON-String genutzt. Das Makro in dieser Zeile muss ein gültiges JSON-Element erzeugen. Bei primitiven Datentypen kann hierfür ein vom Framework bereitgestelltes Makro (JSON\_\-STRUCT\_\-ELEMENT) genutzt werden. Dieses bekommt als ersten Parameter den Namen des zu generierenden Elements. Dieser hat aus dem Parameter des Makros des primitiven Datentyps zu stammen. Somit wird ein JSON-Element mit gleichem Namen wie das Struktur-Element erzeugt. Als zweiten Parameter bekommt das Framework-Makro eine Formatangabe für den primitiven Datentypen. Hier sind alle Formatangaben möglich, die auch bei der Funktion printf() genutzt werden können. Entsprechend dieser Angabe wird aus dem als dritten Parameter übergebenen Wert ein String generiert. Wenn dieser String noch zusätzlich aufbereitet werden muss, um dem JSON-Format zu genügen, so muss eventuell ein zusätzliches Makro erstellt werden. Vor dem Erstellen eines solchen Makros sollte geprüft werden, ob eine Anpassung der Formatangabe ausreichend ist. Müssen beispielsweise lediglich Hochkommas um den generierten String ergänzt werden, so kann dies direkt als Formatangabe geschehen (z.B. \lstinline[language=C,numbers=left,numberstyle=\tiny]!"%p"!), wie es auch bei printf() möglich ist. Der als dritter Parameter übergebene Wert wird aus dem Pointer  json\_struct\_data durch Dereferenzieren und Verweisen auf das untergeordnete Element erzeugt. Das untergeordnete Element hat dabei den gleichen Namen wie der erste Parameter. Der Pointer json\_struct\_data wrid durch das Framework bereitgestellt.

Die vierte Zeile dient beim Serialisieren in einen JSON-String zum Ermitteln der maximal möglichen Länge des JSON-Strings. Für primitive Datentypen stellt das Framework hierfür das Makro JSON\_\-STRUCT\_\-ELEMENT\_\-SIZE zur Verfügung. Dieses Framework-Makro bekommt als ersten Parameter den Namen des Elements übergeben. Dieser muss aus dem Makro des primitiven Datentyps stammen. Nur so wird die Länge des Strings für den Elementnamen passend zum in der dritten Zeile generierten Elementnamen ermittelt. Als zweiten Parameter muss die größtmögliche Länge des Strings für den Wert des primitiven Datentyps übergeben werden. Diese Länge ergibt sich aus dem Wertebereich des Datentyps und dem Verhalten der Formatangabe. Dieses Verhalten ist identisch zu printf(). Dabei darf nie eine einfache Konstante angegeben werden, sofern sich der Wertebereich abhängig von der zugrundeliegenden Architektur (z.B. 32 oder 64 Bit) ändern kann. Für bestimmte Fälle stellt das Framework bereits Makros zur Ermittlung der maximalen Länge eines Variablenwertes. Für die Umwandlung in Dezimalzahlen ist dies JSON\_\-STRUCT\_\-TYPE\_\-SIZE\_\-DEC. Bei diesem Makro muss bei vorzeichenbehafteten Datentypen noch eine Eins für das Vorzeichen im String ergänzt werden. Für die Umwandlung in Hexadezimalzahlen kann das Makro JSON\_\-STRUCT\_\-TYPE\_\-SIZE\_\-HEX genutzt werden. Da hexadezimale Werte im JSON-Format in Hochkommas eingeschlossen werden müssen, muss hier noch der Wert Zwei ergänzt werden.

Die fünfte Zeile dient zum Ermitteln der benötigten Bytes für ein Kopieren in einen frameworkinternen Buffer. Sofern in der sechsten Zeile kein besonderes Verhalten für das Kopieren definiert wird, muss hier für einen primitiven Datentyp kein vom Standard abweichendes Verhalten vorgesehen werden. Das Kopieren wird dann über das Kopieren der übergeordneten Struktur erledigt. Dementsprechend wird das Makro mit einem leeren Ersetzungstext in die fünfte Zeile aufgenommen.

Die sechste Zeile regelt das Kopieren der Daten in einen Buffer. Primitive Datentypen, die nicht auf anderen Speicher verweisen, müssen hier kein Verhalten definieren. Sie werden durch das Kopieren der übergeordneten Struktur kopiert. In diesem Fall muss das Makro mit einem leeren Ersetzungstext in der sechsten Zeile stehen. In allen anderen Fällen müssen komplexe Makros erstellt werden (s.o.).

\subsubsection{Framework Nutzung}
\label{subsubsec:framework_nutzung}

Für das statische Linken muss beim Kompilieren des zu überwachenden Programms der Linker mit der Option -wrap aufgerufen werden und die statische Variante der Wrapper-Bibliothek (libiotrace\_static.a) eingebunden werden. Hierdurch werden alle Aufrufe der zu überwachenden Funktionen auf die Wrapper gelinkt. Zudem werden Aufrufe der überwachten Funktionen aus den Wrappern heraus an die überwachten Funktionen weiter gegeben. Das entwprechend gelinkte Programm kann dann ganz normal gestartet werden. Folgend ein Beispiel für die entsprechende Option des gcc-Compilers für die Funktion close:
\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_CMakeLists.txt}

Für dynamisches Linken kann dagegen das zu überwachende Programm unverändert genutzt werden. Vor dem Starten des Programms muss lediglich die dynamische Variante der Wrapper-Bibliothek (libiotrace\_shared.so) über die Umgebungsvariable LD\_PRELOAD geladen sein. Heirdurch werden die Wrapper vor den überwachten Funktionen geladen. Folgend ein Beispiel für den Firefox als überwachtes Programm. In diesem Beispiel ist noch zusätzlich die Sandbox im Firefox über die Umgebungsvariable MOZ\_\-FAKE\_\-NO\_\-SANDBOX deaktiviert, da die aktivierte Sandbox das Ermitteln einer genauen Systemzeit über entsprechende Kernel-Funktionen verhindert, diese aber für das Loggen durch die Wrapper benötigt werden:
\lstinputlisting[language=C,numbers=left,numberstyle=\tiny]{source/Wrapper_Example_Aufruf.txt}

\chapter{Aktueller Stand}
\label{sec:ergeb}

\section{Wintersemester 2018/2019}
\label{sec:wintersemester_2018_2019}

Alle nötigen Vorarbeiten für die Erstellung der Wrapper sind abgeschlossen \verw{subsec:umsetzung_wrapper}. Die Entwicklungsumgebung und ein CMake-Projekt sind eingerichtet. Zudem sind die grundlegenden architektonischen Entscheidungen getroffen \verw{subsec:architektur_wrapper}. Hierbei wurde auch die geplante Gesamtarchitektur für das ganze System inklusive Analyse und Visualisierung beachtet \verw{subsec:system}.

Durch erste kleine Testprogramme wurde die Funktionsweise der Wrapper erfolgreich getestet. Hierfür wurde ein Programm erstellt, welches in mehreren parallelen Threads die gleichen Funktionen aus der glibc aufruft \verw{sec:testprogramm_openmp}. Dieses Programm wurde dann mit einem dynamischne Wrapper \verw{sec:dynamischer_wrapper_mit_zentraler_buffer} und einem statischen Wrapper \verw{sec:statischer_wrapper} erfolgreich überwacht. Für den dynamischen Wrapper war hierbei ein Laden des Wrappers über die Umgebungsvariable ,,LD\_PRELOAD`` \verw{par:dynamisch_gelinkt} und für den statischen Wrapper ein Linken über Optionen des Linkers \verw{par:statisch_gelinkt} notwendig. Ein Beispiel für das Linken ist im Anhang enthalten \verw{sec:linken_statischer_wrapper}.

Mit der Implementierung der ersten Wrapper wurde bereits begonnen. Diese wird jetzt fortgesetzt. Dabei liegt der Fokus zunächst auf POSIX-IO und MPI-IO.

\section{Sommersemester 2019}
\label{sec:sommersemester_2019}

Für die Implementierung der Wrapper wurde ein Framework geschaffen \verw{subsec:umsetzung_framework}. Dieses ermöglicht das Erstellen von Wrappern für beliebige C-Funktionen. Diese können über das Framework sowohl für statisches als auch für dynamisches Linken bereitgestellt werden. Zudem bietet das Framework einen Automatismus zum Serialisieren von C-Datenstrukturen nach JSON-Strings. Für das Speichern von C-Strukturen und das anschließende Serialisieren und Schreiben derselben stellt das Framework Buffer zur Verfügung. Somit können hier Performanceverluste durch Latenzen, zum Beispiel beim Schreiben, vermieden werden.

Über das Framework wurden 126 Wrapper für File-IO-Funktionen aus der glibc geschaffen. Hierbei wurden Wrapper für standard POSIX-Funktionen und für in Linux verfügbare Erweiterungen umgesetzt.

Mögliche nächste Schritte sind die Erweiterung um weitere Wrapper und die Optimierung des Frameworks. Als weitere Wrapper kommen zunächst noch fehlende File-IO-Funktionen aus der glibc und asynchrone File-IO-Funktionen nach POSIX-Standard aus aio in Frage. Weiterhin ist eine Erweiterung auf MPI-File-IO-Funktionen notwendig. In HPC-Systemen wird standardmäßig parallelisiert. Da hierfür Frameworks wie MPI genutzt werden und diese ihre eigenen optimierten File-IO-Funktionen bereitstellen, müssen diese ebenfalls protokolliert werden, um entsprechend analysiert werden zu können. Das Framework kann hinsichtlich des Serialisierens und Schreibens der C-Strukturen optimiert werden. Insbesondere können diese Vorgänge parallelisiert also in separate Threads/Prozesse ausgelagert werden. Somit würden die gewrappten Funktionen nicht länger durch diese Tätigkeiten belastet. Diesbezüglich kann für das Schreiben auch eine asynchrone File-IO-Funktion genutzt werden. Zudem kann als interner Buffer eine lock-free Datenstruktur genutzt werden.

Da jede bislang geschaffen Funktionalität ausschließlich das Protokollieren von File-IO zum Ziel hat, besteht der nächste große Schritt in der Schaffung von Analysefunktionen für die protokollierten Daten.